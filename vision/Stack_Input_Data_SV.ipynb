{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ebe27452-c2a0-4eb4-a00f-7e917f83b273",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "# !unzip /home/s2120006/TFS/vision/dataset/OneHand_bef_stack.zip\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5ef3f933-83e8-4b63-b19f-5af0cd2e818d",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-13 20:40:16.915309: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-12-13 20:40:19.425013: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/s2120006/miniconda3/lib\n",
      "2022-12-13 20:40:19.425562: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /home/s2120006/miniconda3/lib\n",
      "2022-12-13 20:40:19.425570: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "import os\n",
    "from tensorflow.keras.utils import load_img\n",
    "#from keras.preprocessing.image import load_img\n",
    "from tensorflow.keras.utils import img_to_array\n",
    "# from keras.preprocessing.image import img_to_array\n",
    "import shutil\n",
    "#from keras.preprocessing.sequence import pad_sequences\n",
    "import pickle\n",
    "#from random import randint\n",
    "import random\n",
    "import shutil\n",
    "#import extcolors\n",
    "#from colormap import rgb2hex\n",
    "import h5py\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4db3f4f4-c1f7-4b33-9c91-25b2445b3e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = '/home/s2120006/TFS/vision/dataset/OneHand/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f15174bd-8dc2-4647-bdf3-9f1e95d00fc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "(3398, 45, 224, 224, 3) (3398,)\n",
      "{'6', 'ป', 'อิ', '3', 'ง', '1', 'ม', 'ฏ', '5', 'ต', '2', '4', 'ค', '7', 'บ', 'ณ', 'ถ', 'พ', 'ก', '8', 'ฝ', 'ท', 'ฐ', '40', '80', 'ฆ', 'ร', 'จ', 'อื(คือ)', 'ฬ', 'ฉ', '90', '20', '100', 'ฒ', '100,000', 'อี', 'ด', 'อ', 'ผ', 'ฑ', 'ซ', '0', 'ฌ', 'ใอ', 'น', 'ธ', 'ษ', 'ฮ', '1,000', 'ไอ', 'อึ(นึก)', 'ภ', 'ล', 'ย', '70', 'ข', '50', '10,000', 'ช', 'ศ', 'ส', 'โอ', 'ญ', 'ฟ', '9', 'ว', 'ห', '1,000,000', '30', '10', '60', 'ฎ'}\n"
     ]
    }
   ],
   "source": [
    "#### stack photo and label for LSTM (5 inputs)\n",
    "\n",
    "# num_sub, num_mainfile, subDir, num_files, allfiles, crp_count, crop_all_folder, padding_file, sub_crop_count  = 0,0,0,0,0, 0,0,0,0\n",
    "from numpy import asarray\n",
    "crp_count=0\n",
    "photos = []\n",
    "# seq_name = list()\n",
    "labels = []\n",
    "count, subDir, num_mainfile = 0, 0, 0\n",
    "for subtype_folder in os.listdir(base_path):\n",
    "            # num_sub += 1\n",
    "            subtype_path = base_path + subtype_folder + '/'\n",
    "\n",
    "\n",
    "            for mainfile_folder in os.listdir(subtype_path):\n",
    "                num_mainfile += 1\n",
    "                mainfile_path = subtype_path + mainfile_folder + '/'\n",
    "\n",
    "\n",
    "                # print(mainfile_folder)\n",
    "                for filename in os.listdir(mainfile_path):\n",
    "                    if (filename != '.DS_Store') and (filename != 'desktop.ini'):\n",
    "                        groupFolder = mainfile_path + filename + '/Humand hand/'\n",
    "                        subDir += 1\n",
    "                        count += 1\n",
    "                        # print(filename)\n",
    "                        # print(groupFolder)\n",
    "                        for crp_folder in os.listdir(groupFolder):\n",
    "                            crp_path = groupFolder + crp_folder + '/'\n",
    "                            crp_count += 1\n",
    "                            for padding_folder in os.listdir(crp_path):\n",
    "                                if padding_folder[:3] == 'pad' or padding_folder[:3] == 'dum':\n",
    "                                    padding_path = crp_path + padding_folder + '/'\n",
    "                                    for img_files in os.listdir(padding_path):\n",
    "                                        # img_path = padding_path + img_files\n",
    "                                        # print(img_path)\n",
    "\n",
    "                                        try:\n",
    "                                            img_path = padding_path + img_files\n",
    "                                            photo = load_img(img_path,target_size=(224,224))\n",
    "                                            photo = img_to_array(photo)\n",
    "                                            photos.append(photo)\n",
    "\n",
    "                                        except FileNotFoundError:\n",
    "                                            print('File Error:=>  ', img_path)\n",
    "\n",
    "                        labels.append(mainfile_folder)\n",
    "                        # print(count)\n",
    "\n",
    "            print(num_mainfile)\n",
    "                # labels.append(mainfile_folder)\n",
    "# data = asarray(photos)\n",
    "# labels = asarray(labels)\n",
    "# print(data.shape, labels.shape)\n",
    "# print(labels)\n",
    "\n",
    "photos = np.stack(photos)\n",
    "labels = np.stack(labels)\n",
    "datas = photos.reshape(count,45,224,224,3)\n",
    "print(datas.shape, labels.shape)\n",
    "print(set(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "75f40b47-1249-42c6-aad0-06b2aca3fe44",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 23017236480 into shape (156308,224,224,3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [5], line 57\u001b[0m\n\u001b[1;32m     55\u001b[0m photos \u001b[38;5;241m=\u001b[39m asarray(photos)\n\u001b[1;32m     56\u001b[0m labels \u001b[38;5;241m=\u001b[39m asarray(labels)\n\u001b[0;32m---> 57\u001b[0m datas \u001b[38;5;241m=\u001b[39m \u001b[43mphotos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcount\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m224\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m224\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28mprint\u001b[39m(data\u001b[38;5;241m.\u001b[39mshape, labels\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28mprint\u001b[39m(labels)\n",
      "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 23017236480 into shape (156308,224,224,3)"
     ]
    }
   ],
   "source": [
    "#### stack photo and label for general models (4 inputs)\n",
    "\n",
    "\n",
    "# num_sub, num_mainfile, subDir, num_files, allfiles, crp_count, crop_all_folder, padding_file, sub_crop_count  = 0,0,0,0,0, 0,0,0,0\n",
    "from numpy import asarray\n",
    "crp_count=0\n",
    "photos = []\n",
    "# seq_name = list()\n",
    "labels = []\n",
    "count, subDir, num_mainfile = 0, 0, 0\n",
    "for subtype_folder in os.listdir(base_path):\n",
    "            # num_sub += 1\n",
    "            subtype_path = base_path + subtype_folder + '/'\n",
    "\n",
    "\n",
    "            for mainfile_folder in os.listdir(subtype_path):\n",
    "                num_mainfile += 1\n",
    "                mainfile_path = subtype_path + mainfile_folder + '/'\n",
    "\n",
    "\n",
    "                # print(mainfile_folder)\n",
    "                for filename in os.listdir(mainfile_path):\n",
    "                    if (filename != '.DS_Store') and (filename != 'desktop.ini'):\n",
    "                        groupFolder = mainfile_path + filename + '/Humand hand/'\n",
    "                        subDir += 1\n",
    "                        count += 1\n",
    "                        # print(filename)\n",
    "                        # print(groupFolder)\n",
    "                        for crp_folder in os.listdir(groupFolder):\n",
    "                            crp_path = groupFolder + crp_folder + '/'\n",
    "                            crp_count += 1\n",
    "                            for padding_folder in os.listdir(crp_path):\n",
    "                                if padding_folder[:3] == 'pad' or padding_folder[:3] == 'dum':\n",
    "                                    padding_path = crp_path + padding_folder + '/'\n",
    "                                    for img_files in os.listdir(padding_path):\n",
    "                                        # img_path = padding_path + img_files\n",
    "                                        # print(img_path)\n",
    "                                        count += 1\n",
    "                                        try:\n",
    "                                            img_path = padding_path + img_files\n",
    "                                            photo = load_img(img_path,target_size=(224,224))\n",
    "                                            photo = img_to_array(photo)\n",
    "                                            photos.append(photo)\n",
    "                                            labels.append(mainfile_folder)\n",
    "                                            \n",
    "                                        except FileNotFoundError:\n",
    "                                            print('File Error:=>  ', img_path)\n",
    "\n",
    "                        \n",
    "                            # print(count)\n",
    "\n",
    "                # print(num_mainfile)\n",
    "                # labels.append(mainfile_folder)\n",
    "                \n",
    "photos = asarray(photos)\n",
    "labels = asarray(labels)\n",
    "datas = photos.reshape(count, 224, 224, 3)\n",
    "print(data.shape, labels.shape)\n",
    "print(labels)\n",
    "\n",
    "# photos = np.stack(photos)\n",
    "# labels = np.stack(labels)\n",
    "# datas = photos.reshape(count,45,224,224,3)\n",
    "# print(datas.shape, labels.shape)\n",
    "print(set(labels))\n",
    "\n",
    "np.savez_compressed('/home/s2120006/TFS/vision/dataset/Onehand_Stack_4inputs',data = datas, label = labels)\n",
    "print('******** Done *********')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "af5ce5b8-8fda-4b24-b3ea-fa22b2b83089",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from datetime import datetime\n",
    "# current_dateTime = datetime.now()\n",
    "# current_dateTime = current_dateTime.strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "# print(current_dateTime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "836b9e3c-8bf1-4bf3-abf7-6f942899d623",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e0dcc0b7-a542-47e4-a92f-c210e1a338db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******** Done *********\n"
     ]
    }
   ],
   "source": [
    "np.savez_compressed('/home/s2120006/TFS/vision/dataset/Onehand_Stack',data = datas, label = labels)\n",
    "print('******** Done *********')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daeb1eef-19bb-4273-b527-0d2d547a3052",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59f72991-f667-4695-8adc-4e83824714b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f10e3385-d981-41ae-b68d-6193c6057f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.save('/home/s2120006/TFS/vision/label',labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18d0a431-a9d2-4b66-8e6e-d41f7de685fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "349d9ae8-2807-4525-8e22-1650fb323220",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pre_data = datas\n",
    "# f = open(f'Data_LSTM_OneHand.pkl','wb')\n",
    "# pickle.dump(pre_data,f)\n",
    "# f.close()\n",
    "\n",
    "# print('*******************Done***************')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "be874751-8b94-4fec-9176-f8674189d897",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pre_labels = labels\n",
    "# g = open(f'labels_LSTM_OneHand.pkl','wb')\n",
    "# pickle.dump(pre_labels, g)\n",
    "# g.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97e40c4c-37c2-4ec4-a8be-6e0522f00725",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
