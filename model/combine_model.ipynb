{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "import plotly as cm\n",
    "from pandas_profiling import ProfileReport\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, Dense, MaxPool2D, Dropout, Flatten, AveragePooling2D\n",
    "from tensorflow.keras.utils import Sequence\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, confusion_matrix, recall_score, precision_score\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "import plotly.figure_factory as ff\n",
    "import plotly\n",
    "import plotly.graph_objs as go\n",
    "import pickle\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from statistics import mode, StatisticsError\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import TimeDistributed\n",
    "from keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import regularizers"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "bk_skeleton_onehand = 'D:\\\\Python_Projects\\\\Main_TFS\\\\Dataset_complete\\\\Skeleton_OneHand_54_points_no_V.csv'\n",
    "bk_skeleton_twohand = 'D:\\\\Python_Projects\\\\Main_TFS\\\\Dataset_complete\\\\Skeleton_TwoHand_75_points_no_V.csv'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "df_one = pd.read_csv(bk_skeleton_onehand, engine='python')\n",
    "df_two = pd.read_csv(bk_skeleton_twohand, engine='python')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "  class        x1        y1        z1        x2        y2        z2        x3  \\\n0     0  0.469715  0.440847 -1.146045  0.492933  0.367618 -1.074119  0.506275   \n1     0  0.470880  0.431583 -1.010670  0.493463  0.355553 -0.928780  0.505930   \n2     0  0.470880  0.431583 -1.010670  0.493463  0.355553 -0.928780  0.505930   \n3     0  0.461313  0.441721 -0.895512  0.490067  0.364946 -0.815676  0.505128   \n4     0  0.462009  0.434323 -0.954978  0.490552  0.357484 -0.868968  0.504614   \n\n         y3        z3  ...       z51       x52       y52       z52       x53  \\\n0  0.367054 -1.074444  ... -0.053524  0.399725  0.730864 -0.062620  0.427866   \n1  0.352796 -0.929152  ... -0.048000  0.398512  0.606266 -0.058852  0.428957   \n2  0.352796 -0.929152  ... -0.048000  0.398512  0.606266 -0.058852  0.428957   \n3  0.363007 -0.816117  ... -0.038509  0.395845  0.572608 -0.049951  0.427251   \n4  0.355328 -0.869323  ... -0.038847  0.392572  0.538630 -0.047879  0.424092   \n\n        y53       z53       x54       y54       z54  \n0  0.751528 -0.060393  0.447253  0.774449 -0.058090  \n1  0.621372 -0.059092  0.449393  0.640706 -0.057821  \n2  0.621372 -0.059092  0.449393  0.640706 -0.057821  \n3  0.590068 -0.049887  0.448360  0.611298 -0.047701  \n4  0.548410 -0.046750  0.444159  0.566794 -0.043640  \n\n[5 rows x 163 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>class</th>\n      <th>x1</th>\n      <th>y1</th>\n      <th>z1</th>\n      <th>x2</th>\n      <th>y2</th>\n      <th>z2</th>\n      <th>x3</th>\n      <th>y3</th>\n      <th>z3</th>\n      <th>...</th>\n      <th>z51</th>\n      <th>x52</th>\n      <th>y52</th>\n      <th>z52</th>\n      <th>x53</th>\n      <th>y53</th>\n      <th>z53</th>\n      <th>x54</th>\n      <th>y54</th>\n      <th>z54</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0.469715</td>\n      <td>0.440847</td>\n      <td>-1.146045</td>\n      <td>0.492933</td>\n      <td>0.367618</td>\n      <td>-1.074119</td>\n      <td>0.506275</td>\n      <td>0.367054</td>\n      <td>-1.074444</td>\n      <td>...</td>\n      <td>-0.053524</td>\n      <td>0.399725</td>\n      <td>0.730864</td>\n      <td>-0.062620</td>\n      <td>0.427866</td>\n      <td>0.751528</td>\n      <td>-0.060393</td>\n      <td>0.447253</td>\n      <td>0.774449</td>\n      <td>-0.058090</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>0.470880</td>\n      <td>0.431583</td>\n      <td>-1.010670</td>\n      <td>0.493463</td>\n      <td>0.355553</td>\n      <td>-0.928780</td>\n      <td>0.505930</td>\n      <td>0.352796</td>\n      <td>-0.929152</td>\n      <td>...</td>\n      <td>-0.048000</td>\n      <td>0.398512</td>\n      <td>0.606266</td>\n      <td>-0.058852</td>\n      <td>0.428957</td>\n      <td>0.621372</td>\n      <td>-0.059092</td>\n      <td>0.449393</td>\n      <td>0.640706</td>\n      <td>-0.057821</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>0.470880</td>\n      <td>0.431583</td>\n      <td>-1.010670</td>\n      <td>0.493463</td>\n      <td>0.355553</td>\n      <td>-0.928780</td>\n      <td>0.505930</td>\n      <td>0.352796</td>\n      <td>-0.929152</td>\n      <td>...</td>\n      <td>-0.048000</td>\n      <td>0.398512</td>\n      <td>0.606266</td>\n      <td>-0.058852</td>\n      <td>0.428957</td>\n      <td>0.621372</td>\n      <td>-0.059092</td>\n      <td>0.449393</td>\n      <td>0.640706</td>\n      <td>-0.057821</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>0.461313</td>\n      <td>0.441721</td>\n      <td>-0.895512</td>\n      <td>0.490067</td>\n      <td>0.364946</td>\n      <td>-0.815676</td>\n      <td>0.505128</td>\n      <td>0.363007</td>\n      <td>-0.816117</td>\n      <td>...</td>\n      <td>-0.038509</td>\n      <td>0.395845</td>\n      <td>0.572608</td>\n      <td>-0.049951</td>\n      <td>0.427251</td>\n      <td>0.590068</td>\n      <td>-0.049887</td>\n      <td>0.448360</td>\n      <td>0.611298</td>\n      <td>-0.047701</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>0.462009</td>\n      <td>0.434323</td>\n      <td>-0.954978</td>\n      <td>0.490552</td>\n      <td>0.357484</td>\n      <td>-0.868968</td>\n      <td>0.504614</td>\n      <td>0.355328</td>\n      <td>-0.869323</td>\n      <td>...</td>\n      <td>-0.038847</td>\n      <td>0.392572</td>\n      <td>0.538630</td>\n      <td>-0.047879</td>\n      <td>0.424092</td>\n      <td>0.548410</td>\n      <td>-0.046750</td>\n      <td>0.444159</td>\n      <td>0.566794</td>\n      <td>-0.043640</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 163 columns</p>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_one.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "  class        x1        y1        z1        x2        y2        z2        x3  \\\n0    อ่  0.434110  0.298331 -1.035047  0.461011  0.239869 -0.973024  0.477499   \n1    อ่  0.429909  0.299091 -1.033196  0.457929  0.241853 -0.964616  0.474237   \n2    อ่  0.429909  0.299091 -1.033196  0.457929  0.241853 -0.964616  0.474237   \n3    อ่  0.432813  0.310793 -1.206027  0.460014  0.253977 -1.139681  0.475536   \n4    อ่  0.437205  0.306630 -1.133030  0.462581  0.252750 -1.060267  0.477573   \n\n         y3        z3  ...       z72       x73       y73       z73       x74  \\\n0  0.243439 -0.973308  ...       NaN       NaN       NaN       NaN       NaN   \n1  0.243988 -0.964898  ... -0.015277  0.705914  0.929784 -0.020854  0.714973   \n2  0.243988 -0.964898  ... -0.015277  0.705914  0.929784 -0.020854  0.714973   \n3  0.256214 -1.139858  ... -0.025833  0.697252  0.873881 -0.033462  0.707033   \n4  0.254981 -1.060502  ... -0.021447  0.692508  0.823403 -0.029377  0.701794   \n\n        y74       z74       x75       y75       z75  \n0       NaN       NaN       NaN       NaN       NaN  \n1  0.895617 -0.020210  0.719473  0.867781 -0.019419  \n2  0.895617 -0.020210  0.719473  0.867781 -0.019419  \n3  0.841776 -0.032931  0.713368  0.814074 -0.031750  \n4  0.792851 -0.029400  0.709057  0.765694 -0.028588  \n\n[5 rows x 226 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>class</th>\n      <th>x1</th>\n      <th>y1</th>\n      <th>z1</th>\n      <th>x2</th>\n      <th>y2</th>\n      <th>z2</th>\n      <th>x3</th>\n      <th>y3</th>\n      <th>z3</th>\n      <th>...</th>\n      <th>z72</th>\n      <th>x73</th>\n      <th>y73</th>\n      <th>z73</th>\n      <th>x74</th>\n      <th>y74</th>\n      <th>z74</th>\n      <th>x75</th>\n      <th>y75</th>\n      <th>z75</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>อ่</td>\n      <td>0.434110</td>\n      <td>0.298331</td>\n      <td>-1.035047</td>\n      <td>0.461011</td>\n      <td>0.239869</td>\n      <td>-0.973024</td>\n      <td>0.477499</td>\n      <td>0.243439</td>\n      <td>-0.973308</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>อ่</td>\n      <td>0.429909</td>\n      <td>0.299091</td>\n      <td>-1.033196</td>\n      <td>0.457929</td>\n      <td>0.241853</td>\n      <td>-0.964616</td>\n      <td>0.474237</td>\n      <td>0.243988</td>\n      <td>-0.964898</td>\n      <td>...</td>\n      <td>-0.015277</td>\n      <td>0.705914</td>\n      <td>0.929784</td>\n      <td>-0.020854</td>\n      <td>0.714973</td>\n      <td>0.895617</td>\n      <td>-0.020210</td>\n      <td>0.719473</td>\n      <td>0.867781</td>\n      <td>-0.019419</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>อ่</td>\n      <td>0.429909</td>\n      <td>0.299091</td>\n      <td>-1.033196</td>\n      <td>0.457929</td>\n      <td>0.241853</td>\n      <td>-0.964616</td>\n      <td>0.474237</td>\n      <td>0.243988</td>\n      <td>-0.964898</td>\n      <td>...</td>\n      <td>-0.015277</td>\n      <td>0.705914</td>\n      <td>0.929784</td>\n      <td>-0.020854</td>\n      <td>0.714973</td>\n      <td>0.895617</td>\n      <td>-0.020210</td>\n      <td>0.719473</td>\n      <td>0.867781</td>\n      <td>-0.019419</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>อ่</td>\n      <td>0.432813</td>\n      <td>0.310793</td>\n      <td>-1.206027</td>\n      <td>0.460014</td>\n      <td>0.253977</td>\n      <td>-1.139681</td>\n      <td>0.475536</td>\n      <td>0.256214</td>\n      <td>-1.139858</td>\n      <td>...</td>\n      <td>-0.025833</td>\n      <td>0.697252</td>\n      <td>0.873881</td>\n      <td>-0.033462</td>\n      <td>0.707033</td>\n      <td>0.841776</td>\n      <td>-0.032931</td>\n      <td>0.713368</td>\n      <td>0.814074</td>\n      <td>-0.031750</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>อ่</td>\n      <td>0.437205</td>\n      <td>0.306630</td>\n      <td>-1.133030</td>\n      <td>0.462581</td>\n      <td>0.252750</td>\n      <td>-1.060267</td>\n      <td>0.477573</td>\n      <td>0.254981</td>\n      <td>-1.060502</td>\n      <td>...</td>\n      <td>-0.021447</td>\n      <td>0.692508</td>\n      <td>0.823403</td>\n      <td>-0.029377</td>\n      <td>0.701794</td>\n      <td>0.792851</td>\n      <td>-0.029400</td>\n      <td>0.709057</td>\n      <td>0.765694</td>\n      <td>-0.028588</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 226 columns</p>\n</div>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_two.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_one.isnull().values.any()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_two.isnull().values.any()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "292635"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_one.isnull().sum().sum()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "508284"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_two.isnull().sum().sum()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class       0\n",
      "x1          0\n",
      "y1          0\n",
      "z1          0\n",
      "x2          0\n",
      "         ... \n",
      "y53      4645\n",
      "z53      4645\n",
      "x54      4645\n",
      "y54      4645\n",
      "z54      4645\n",
      "Length: 163, dtype: int64 508284\n"
     ]
    }
   ],
   "source": [
    "print(df_one.isnull().sum(), df_two.isnull().sum().sum())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "       class        x1        y1        z1        x2        y2        z2  \\\n0          0  0.469715  0.440847 -1.146045  0.492933  0.367618 -1.074119   \n1          0  0.470880  0.431583 -1.010670  0.493463  0.355553 -0.928780   \n2          0  0.470880  0.431583 -1.010670  0.493463  0.355553 -0.928780   \n3          0  0.461313  0.441721 -0.895512  0.490067  0.364946 -0.815676   \n4          0  0.462009  0.434323 -0.954978  0.490552  0.357484 -0.868968   \n...      ...       ...       ...       ...       ...       ...       ...   \n150095    ไอ  0.528125  0.373132 -0.992049  0.547567  0.315567 -0.916250   \n150096    ไอ  0.525108  0.370276 -0.992426  0.546147  0.315484 -0.917663   \n150097    ไอ  0.527792  0.370975 -1.054370  0.544327  0.313867 -0.981253   \n150098    ไอ  0.527792  0.370975 -1.054370  0.544327  0.313867 -0.981253   \n150099    ไอ  0.524986  0.361204 -1.097511  0.544687  0.304384 -1.024949   \n\n              x3        y3        z3  ...       z51       x52       y52  \\\n0       0.506275  0.367054 -1.074444  ... -0.053524  0.399725  0.730864   \n1       0.505930  0.352796 -0.929152  ... -0.048000  0.398512  0.606266   \n2       0.505930  0.352796 -0.929152  ... -0.048000  0.398512  0.606266   \n3       0.505128  0.363007 -0.816117  ... -0.038509  0.395845  0.572608   \n4       0.504614  0.355328 -0.869323  ... -0.038847  0.392572  0.538630   \n...          ...       ...       ...  ...       ...       ...       ...   \n150095  0.562286  0.317489 -0.916352  ... -0.028968  0.291391  0.640639   \n150096  0.561741  0.318271 -0.917825  ... -0.037876  0.269125  0.701057   \n150097  0.558664  0.314726 -0.981566  ... -0.033339  0.254433  0.791060   \n150098  0.558664  0.314726 -0.981566  ... -0.033339  0.254433  0.791060   \n150099  0.559115  0.306688 -1.025168  ... -0.031130  0.237031  0.866545   \n\n             z52       x53       y53       z53       x54       y54       z54  \n0      -0.062620  0.427866  0.751528 -0.060393  0.447253  0.774449 -0.058090  \n1      -0.058852  0.428957  0.621372 -0.059092  0.449393  0.640706 -0.057821  \n2      -0.058852  0.428957  0.621372 -0.059092  0.449393  0.640706 -0.057821  \n3      -0.049951  0.427251  0.590068 -0.049887  0.448360  0.611298 -0.047701  \n4      -0.047879  0.424092  0.548410 -0.046750  0.444159  0.566794 -0.043640  \n...          ...       ...       ...       ...       ...       ...       ...  \n150095 -0.037794  0.303840  0.616979 -0.037350  0.316877  0.597338 -0.033791  \n150096 -0.056327  0.279851  0.691119 -0.060445  0.289750  0.684217 -0.059406  \n150097 -0.041410  0.265023  0.817268 -0.038859  0.269435  0.841274 -0.033614  \n150098 -0.041410  0.265023  0.817268 -0.038859  0.269435  0.841274 -0.033614  \n150099 -0.038810  0.246614  0.893922 -0.036005  0.250141  0.914375 -0.030636  \n\n[145455 rows x 163 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>class</th>\n      <th>x1</th>\n      <th>y1</th>\n      <th>z1</th>\n      <th>x2</th>\n      <th>y2</th>\n      <th>z2</th>\n      <th>x3</th>\n      <th>y3</th>\n      <th>z3</th>\n      <th>...</th>\n      <th>z51</th>\n      <th>x52</th>\n      <th>y52</th>\n      <th>z52</th>\n      <th>x53</th>\n      <th>y53</th>\n      <th>z53</th>\n      <th>x54</th>\n      <th>y54</th>\n      <th>z54</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>0.469715</td>\n      <td>0.440847</td>\n      <td>-1.146045</td>\n      <td>0.492933</td>\n      <td>0.367618</td>\n      <td>-1.074119</td>\n      <td>0.506275</td>\n      <td>0.367054</td>\n      <td>-1.074444</td>\n      <td>...</td>\n      <td>-0.053524</td>\n      <td>0.399725</td>\n      <td>0.730864</td>\n      <td>-0.062620</td>\n      <td>0.427866</td>\n      <td>0.751528</td>\n      <td>-0.060393</td>\n      <td>0.447253</td>\n      <td>0.774449</td>\n      <td>-0.058090</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>0.470880</td>\n      <td>0.431583</td>\n      <td>-1.010670</td>\n      <td>0.493463</td>\n      <td>0.355553</td>\n      <td>-0.928780</td>\n      <td>0.505930</td>\n      <td>0.352796</td>\n      <td>-0.929152</td>\n      <td>...</td>\n      <td>-0.048000</td>\n      <td>0.398512</td>\n      <td>0.606266</td>\n      <td>-0.058852</td>\n      <td>0.428957</td>\n      <td>0.621372</td>\n      <td>-0.059092</td>\n      <td>0.449393</td>\n      <td>0.640706</td>\n      <td>-0.057821</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>0.470880</td>\n      <td>0.431583</td>\n      <td>-1.010670</td>\n      <td>0.493463</td>\n      <td>0.355553</td>\n      <td>-0.928780</td>\n      <td>0.505930</td>\n      <td>0.352796</td>\n      <td>-0.929152</td>\n      <td>...</td>\n      <td>-0.048000</td>\n      <td>0.398512</td>\n      <td>0.606266</td>\n      <td>-0.058852</td>\n      <td>0.428957</td>\n      <td>0.621372</td>\n      <td>-0.059092</td>\n      <td>0.449393</td>\n      <td>0.640706</td>\n      <td>-0.057821</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>0.461313</td>\n      <td>0.441721</td>\n      <td>-0.895512</td>\n      <td>0.490067</td>\n      <td>0.364946</td>\n      <td>-0.815676</td>\n      <td>0.505128</td>\n      <td>0.363007</td>\n      <td>-0.816117</td>\n      <td>...</td>\n      <td>-0.038509</td>\n      <td>0.395845</td>\n      <td>0.572608</td>\n      <td>-0.049951</td>\n      <td>0.427251</td>\n      <td>0.590068</td>\n      <td>-0.049887</td>\n      <td>0.448360</td>\n      <td>0.611298</td>\n      <td>-0.047701</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>0.462009</td>\n      <td>0.434323</td>\n      <td>-0.954978</td>\n      <td>0.490552</td>\n      <td>0.357484</td>\n      <td>-0.868968</td>\n      <td>0.504614</td>\n      <td>0.355328</td>\n      <td>-0.869323</td>\n      <td>...</td>\n      <td>-0.038847</td>\n      <td>0.392572</td>\n      <td>0.538630</td>\n      <td>-0.047879</td>\n      <td>0.424092</td>\n      <td>0.548410</td>\n      <td>-0.046750</td>\n      <td>0.444159</td>\n      <td>0.566794</td>\n      <td>-0.043640</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>150095</th>\n      <td>ไอ</td>\n      <td>0.528125</td>\n      <td>0.373132</td>\n      <td>-0.992049</td>\n      <td>0.547567</td>\n      <td>0.315567</td>\n      <td>-0.916250</td>\n      <td>0.562286</td>\n      <td>0.317489</td>\n      <td>-0.916352</td>\n      <td>...</td>\n      <td>-0.028968</td>\n      <td>0.291391</td>\n      <td>0.640639</td>\n      <td>-0.037794</td>\n      <td>0.303840</td>\n      <td>0.616979</td>\n      <td>-0.037350</td>\n      <td>0.316877</td>\n      <td>0.597338</td>\n      <td>-0.033791</td>\n    </tr>\n    <tr>\n      <th>150096</th>\n      <td>ไอ</td>\n      <td>0.525108</td>\n      <td>0.370276</td>\n      <td>-0.992426</td>\n      <td>0.546147</td>\n      <td>0.315484</td>\n      <td>-0.917663</td>\n      <td>0.561741</td>\n      <td>0.318271</td>\n      <td>-0.917825</td>\n      <td>...</td>\n      <td>-0.037876</td>\n      <td>0.269125</td>\n      <td>0.701057</td>\n      <td>-0.056327</td>\n      <td>0.279851</td>\n      <td>0.691119</td>\n      <td>-0.060445</td>\n      <td>0.289750</td>\n      <td>0.684217</td>\n      <td>-0.059406</td>\n    </tr>\n    <tr>\n      <th>150097</th>\n      <td>ไอ</td>\n      <td>0.527792</td>\n      <td>0.370975</td>\n      <td>-1.054370</td>\n      <td>0.544327</td>\n      <td>0.313867</td>\n      <td>-0.981253</td>\n      <td>0.558664</td>\n      <td>0.314726</td>\n      <td>-0.981566</td>\n      <td>...</td>\n      <td>-0.033339</td>\n      <td>0.254433</td>\n      <td>0.791060</td>\n      <td>-0.041410</td>\n      <td>0.265023</td>\n      <td>0.817268</td>\n      <td>-0.038859</td>\n      <td>0.269435</td>\n      <td>0.841274</td>\n      <td>-0.033614</td>\n    </tr>\n    <tr>\n      <th>150098</th>\n      <td>ไอ</td>\n      <td>0.527792</td>\n      <td>0.370975</td>\n      <td>-1.054370</td>\n      <td>0.544327</td>\n      <td>0.313867</td>\n      <td>-0.981253</td>\n      <td>0.558664</td>\n      <td>0.314726</td>\n      <td>-0.981566</td>\n      <td>...</td>\n      <td>-0.033339</td>\n      <td>0.254433</td>\n      <td>0.791060</td>\n      <td>-0.041410</td>\n      <td>0.265023</td>\n      <td>0.817268</td>\n      <td>-0.038859</td>\n      <td>0.269435</td>\n      <td>0.841274</td>\n      <td>-0.033614</td>\n    </tr>\n    <tr>\n      <th>150099</th>\n      <td>ไอ</td>\n      <td>0.524986</td>\n      <td>0.361204</td>\n      <td>-1.097511</td>\n      <td>0.544687</td>\n      <td>0.304384</td>\n      <td>-1.024949</td>\n      <td>0.559115</td>\n      <td>0.306688</td>\n      <td>-1.025168</td>\n      <td>...</td>\n      <td>-0.031130</td>\n      <td>0.237031</td>\n      <td>0.866545</td>\n      <td>-0.038810</td>\n      <td>0.246614</td>\n      <td>0.893922</td>\n      <td>-0.036005</td>\n      <td>0.250141</td>\n      <td>0.914375</td>\n      <td>-0.030636</td>\n    </tr>\n  </tbody>\n</table>\n<p>145455 rows × 163 columns</p>\n</div>"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove NaN columns\n",
    "df_one_drop_ax0 = df_one.dropna(axis=0)\n",
    "df_one_drop_ax0"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "           class        x1        y1        z1        x2        y2        z2  \\\n1             อ่  0.429909  0.299091 -1.033196  0.457929  0.241853 -0.964616   \n2             อ่  0.429909  0.299091 -1.033196  0.457929  0.241853 -0.964616   \n3             อ่  0.432813  0.310793 -1.206027  0.460014  0.253977 -1.139681   \n4             อ่  0.437205  0.306630 -1.133030  0.462581  0.252750 -1.060267   \n5             อ่  0.437205  0.306630 -1.133030  0.462581  0.252750 -1.060267   \n...          ...       ...       ...       ...       ...       ...       ...   \n35230  ไม้ไต่คู้  0.511456  0.460191 -0.959940  0.534037  0.401124 -0.899052   \n35231  ไม้ไต่คู้  0.501599  0.458881 -1.124302  0.526439  0.400657 -1.055216   \n35232  ไม้ไต่คู้  0.505169  0.450338 -1.266487  0.532236  0.391213 -1.192186   \n35233  ไม้ไต่คู้  0.518348  0.452888 -1.254290  0.540892  0.397112 -1.181628   \n35234  ไม้ไต่คู้  0.522974  0.458728 -1.299674  0.544999  0.402066 -1.227341   \n\n             x3        y3        z3  ...       z72       x73       y73  \\\n1      0.474237  0.243988 -0.964898  ... -0.015277  0.705914  0.929784   \n2      0.474237  0.243988 -0.964898  ... -0.015277  0.705914  0.929784   \n3      0.475536  0.256214 -1.139858  ... -0.025833  0.697252  0.873881   \n4      0.477573  0.254981 -1.060502  ... -0.021447  0.692508  0.823403   \n5      0.477573  0.254981 -1.060502  ... -0.021447  0.692508  0.823403   \n...         ...       ...       ...  ...       ...       ...       ...   \n35230  0.548146  0.401731 -0.898836  ... -0.039919  0.809364  0.820627   \n35231  0.540674  0.401736 -1.055150  ... -0.043934  0.785507  0.907059   \n35232  0.547755  0.393168 -1.192205  ... -0.037867  0.773673  0.957604   \n35233  0.555048  0.398733 -1.181709  ... -0.029353  0.762456  0.991850   \n35234  0.558838  0.402731 -1.227251  ... -0.022544  0.722687  1.041104   \n\n            z73       x74       y74       z74       x75       y75       z75  \n1     -0.020854  0.714973  0.895617 -0.020210  0.719473  0.867781 -0.019419  \n2     -0.020854  0.714973  0.895617 -0.020210  0.719473  0.867781 -0.019419  \n3     -0.033462  0.707033  0.841776 -0.032931  0.713368  0.814074 -0.031750  \n4     -0.029377  0.701794  0.792851 -0.029400  0.709057  0.765694 -0.028588  \n5     -0.029377  0.701794  0.792851 -0.029400  0.709057  0.765694 -0.028588  \n...         ...       ...       ...       ...       ...       ...       ...  \n35230 -0.052186  0.828242  0.795007 -0.057392  0.844519  0.771788 -0.060988  \n35231 -0.058207  0.802646  0.886843 -0.061276  0.817798  0.866778 -0.062948  \n35232 -0.047840  0.788576  0.940628 -0.046659  0.799739  0.923667 -0.045932  \n35233 -0.037508  0.779295  0.966001 -0.036288  0.792470  0.945838 -0.035624  \n35234 -0.026217  0.734203  1.022373 -0.022036  0.742804  1.011384 -0.020418  \n\n[29011 rows x 226 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>class</th>\n      <th>x1</th>\n      <th>y1</th>\n      <th>z1</th>\n      <th>x2</th>\n      <th>y2</th>\n      <th>z2</th>\n      <th>x3</th>\n      <th>y3</th>\n      <th>z3</th>\n      <th>...</th>\n      <th>z72</th>\n      <th>x73</th>\n      <th>y73</th>\n      <th>z73</th>\n      <th>x74</th>\n      <th>y74</th>\n      <th>z74</th>\n      <th>x75</th>\n      <th>y75</th>\n      <th>z75</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>อ่</td>\n      <td>0.429909</td>\n      <td>0.299091</td>\n      <td>-1.033196</td>\n      <td>0.457929</td>\n      <td>0.241853</td>\n      <td>-0.964616</td>\n      <td>0.474237</td>\n      <td>0.243988</td>\n      <td>-0.964898</td>\n      <td>...</td>\n      <td>-0.015277</td>\n      <td>0.705914</td>\n      <td>0.929784</td>\n      <td>-0.020854</td>\n      <td>0.714973</td>\n      <td>0.895617</td>\n      <td>-0.020210</td>\n      <td>0.719473</td>\n      <td>0.867781</td>\n      <td>-0.019419</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>อ่</td>\n      <td>0.429909</td>\n      <td>0.299091</td>\n      <td>-1.033196</td>\n      <td>0.457929</td>\n      <td>0.241853</td>\n      <td>-0.964616</td>\n      <td>0.474237</td>\n      <td>0.243988</td>\n      <td>-0.964898</td>\n      <td>...</td>\n      <td>-0.015277</td>\n      <td>0.705914</td>\n      <td>0.929784</td>\n      <td>-0.020854</td>\n      <td>0.714973</td>\n      <td>0.895617</td>\n      <td>-0.020210</td>\n      <td>0.719473</td>\n      <td>0.867781</td>\n      <td>-0.019419</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>อ่</td>\n      <td>0.432813</td>\n      <td>0.310793</td>\n      <td>-1.206027</td>\n      <td>0.460014</td>\n      <td>0.253977</td>\n      <td>-1.139681</td>\n      <td>0.475536</td>\n      <td>0.256214</td>\n      <td>-1.139858</td>\n      <td>...</td>\n      <td>-0.025833</td>\n      <td>0.697252</td>\n      <td>0.873881</td>\n      <td>-0.033462</td>\n      <td>0.707033</td>\n      <td>0.841776</td>\n      <td>-0.032931</td>\n      <td>0.713368</td>\n      <td>0.814074</td>\n      <td>-0.031750</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>อ่</td>\n      <td>0.437205</td>\n      <td>0.306630</td>\n      <td>-1.133030</td>\n      <td>0.462581</td>\n      <td>0.252750</td>\n      <td>-1.060267</td>\n      <td>0.477573</td>\n      <td>0.254981</td>\n      <td>-1.060502</td>\n      <td>...</td>\n      <td>-0.021447</td>\n      <td>0.692508</td>\n      <td>0.823403</td>\n      <td>-0.029377</td>\n      <td>0.701794</td>\n      <td>0.792851</td>\n      <td>-0.029400</td>\n      <td>0.709057</td>\n      <td>0.765694</td>\n      <td>-0.028588</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>อ่</td>\n      <td>0.437205</td>\n      <td>0.306630</td>\n      <td>-1.133030</td>\n      <td>0.462581</td>\n      <td>0.252750</td>\n      <td>-1.060267</td>\n      <td>0.477573</td>\n      <td>0.254981</td>\n      <td>-1.060502</td>\n      <td>...</td>\n      <td>-0.021447</td>\n      <td>0.692508</td>\n      <td>0.823403</td>\n      <td>-0.029377</td>\n      <td>0.701794</td>\n      <td>0.792851</td>\n      <td>-0.029400</td>\n      <td>0.709057</td>\n      <td>0.765694</td>\n      <td>-0.028588</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>35230</th>\n      <td>ไม้ไต่คู้</td>\n      <td>0.511456</td>\n      <td>0.460191</td>\n      <td>-0.959940</td>\n      <td>0.534037</td>\n      <td>0.401124</td>\n      <td>-0.899052</td>\n      <td>0.548146</td>\n      <td>0.401731</td>\n      <td>-0.898836</td>\n      <td>...</td>\n      <td>-0.039919</td>\n      <td>0.809364</td>\n      <td>0.820627</td>\n      <td>-0.052186</td>\n      <td>0.828242</td>\n      <td>0.795007</td>\n      <td>-0.057392</td>\n      <td>0.844519</td>\n      <td>0.771788</td>\n      <td>-0.060988</td>\n    </tr>\n    <tr>\n      <th>35231</th>\n      <td>ไม้ไต่คู้</td>\n      <td>0.501599</td>\n      <td>0.458881</td>\n      <td>-1.124302</td>\n      <td>0.526439</td>\n      <td>0.400657</td>\n      <td>-1.055216</td>\n      <td>0.540674</td>\n      <td>0.401736</td>\n      <td>-1.055150</td>\n      <td>...</td>\n      <td>-0.043934</td>\n      <td>0.785507</td>\n      <td>0.907059</td>\n      <td>-0.058207</td>\n      <td>0.802646</td>\n      <td>0.886843</td>\n      <td>-0.061276</td>\n      <td>0.817798</td>\n      <td>0.866778</td>\n      <td>-0.062948</td>\n    </tr>\n    <tr>\n      <th>35232</th>\n      <td>ไม้ไต่คู้</td>\n      <td>0.505169</td>\n      <td>0.450338</td>\n      <td>-1.266487</td>\n      <td>0.532236</td>\n      <td>0.391213</td>\n      <td>-1.192186</td>\n      <td>0.547755</td>\n      <td>0.393168</td>\n      <td>-1.192205</td>\n      <td>...</td>\n      <td>-0.037867</td>\n      <td>0.773673</td>\n      <td>0.957604</td>\n      <td>-0.047840</td>\n      <td>0.788576</td>\n      <td>0.940628</td>\n      <td>-0.046659</td>\n      <td>0.799739</td>\n      <td>0.923667</td>\n      <td>-0.045932</td>\n    </tr>\n    <tr>\n      <th>35233</th>\n      <td>ไม้ไต่คู้</td>\n      <td>0.518348</td>\n      <td>0.452888</td>\n      <td>-1.254290</td>\n      <td>0.540892</td>\n      <td>0.397112</td>\n      <td>-1.181628</td>\n      <td>0.555048</td>\n      <td>0.398733</td>\n      <td>-1.181709</td>\n      <td>...</td>\n      <td>-0.029353</td>\n      <td>0.762456</td>\n      <td>0.991850</td>\n      <td>-0.037508</td>\n      <td>0.779295</td>\n      <td>0.966001</td>\n      <td>-0.036288</td>\n      <td>0.792470</td>\n      <td>0.945838</td>\n      <td>-0.035624</td>\n    </tr>\n    <tr>\n      <th>35234</th>\n      <td>ไม้ไต่คู้</td>\n      <td>0.522974</td>\n      <td>0.458728</td>\n      <td>-1.299674</td>\n      <td>0.544999</td>\n      <td>0.402066</td>\n      <td>-1.227341</td>\n      <td>0.558838</td>\n      <td>0.402731</td>\n      <td>-1.227251</td>\n      <td>...</td>\n      <td>-0.022544</td>\n      <td>0.722687</td>\n      <td>1.041104</td>\n      <td>-0.026217</td>\n      <td>0.734203</td>\n      <td>1.022373</td>\n      <td>-0.022036</td>\n      <td>0.742804</td>\n      <td>1.011384</td>\n      <td>-0.020418</td>\n    </tr>\n  </tbody>\n</table>\n<p>29011 rows × 226 columns</p>\n</div>"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove NaN columns\n",
    "df_two_drop_ax0 = df_two.dropna(axis=0)\n",
    "df_two_drop_ax0"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_one.isnull().values.any()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_two.isnull().values.any()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class    0\n",
      "x1       0\n",
      "y1       0\n",
      "z1       0\n",
      "x2       0\n",
      "        ..\n",
      "y53      0\n",
      "z53      0\n",
      "x54      0\n",
      "y54      0\n",
      "z54      0\n",
      "Length: 163, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df_one_drop_ax0.isnull().sum())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class    0\n",
      "x1       0\n",
      "y1       0\n",
      "z1       0\n",
      "x2       0\n",
      "        ..\n",
      "y74      0\n",
      "z74      0\n",
      "x75      0\n",
      "y75      0\n",
      "z75      0\n",
      "Length: 226, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df_two_drop_ax0.isnull().sum())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One_Feature = (145455, 162)  ; One_Label = (145455,)\n",
      "{'ฌ', '4', 'น', 'ศ', 'ษ', '1,000', '1,000,000', 'ก', 'ซ', '100,000', 'ฒ', 'ถ', 'ร', '100', '6', 'ณ', '30', 'ฝ', 'ฮ', 'อื(คือ)', '2', '8', 'ท', 'ล', '90', 'อิ', 'ช', '3', 'ง', 'ภ', 'ข', 'ธ', 'ฬ', '10', '10,000', 'ว', '7', '60', 'ญ', 'ไอ', 'ฐ', '40', 'ผ', '1', 'ใอ', 'จ', 'โอ', 'ด', 'ต', 'พ', '0', '20', '9', 'ฎ', 'ส', 'อ', '5', '80', 'ฑ', 'อึ(นึก)', 'ค', '70', 'ย', 'ห', '50', 'บ', 'ฆ', 'ม', 'ฉ', 'ฟ', 'อี', 'ป', 'ฏ'}\n",
      "---------------------------------------------------------------------------\n",
      "Two_Feature = (29011, 225)  ; Two_Label = (29011,)\n",
      "{'ทัณฑฆาต', 'อะ', 'อำ', 'อู', 'ฤ', 'อ๋', 'อุ', 'เอ', 'แอ', 'ไม้ไต่คู้', 'อา', 'ฯ', 'อ้', 'อ๊', 'ไม้หันอากาศ', 'อ่'}\n"
     ]
    }
   ],
   "source": [
    "one_feature = df_one_drop_ax0.iloc[:, 1:]\n",
    "one_label = df_one_drop_ax0.iloc[:, 0]\n",
    "print(f'One_Feature = {one_feature.shape}  ; One_Label = {one_label.shape}')\n",
    "print(set(one_label))\n",
    "print('-'*75)\n",
    "two_feature = df_two_drop_ax0.iloc[:, 1:]\n",
    "two_label = df_two_drop_ax0.iloc[:, 0]\n",
    "print(f'Two_Feature = {two_feature.shape}  ; Two_Label = {two_label.shape}')\n",
    "print(set(two_label))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "              x1        y1        z1        x2        y2        z2        x3  \\\n0       0.469715  0.440847 -1.146045  0.492933  0.367618 -1.074119  0.506275   \n1       0.470880  0.431583 -1.010670  0.493463  0.355553 -0.928780  0.505930   \n2       0.470880  0.431583 -1.010670  0.493463  0.355553 -0.928780  0.505930   \n3       0.461313  0.441721 -0.895512  0.490067  0.364946 -0.815676  0.505128   \n4       0.462009  0.434323 -0.954978  0.490552  0.357484 -0.868968  0.504614   \n...          ...       ...       ...       ...       ...       ...       ...   \n150095  0.528125  0.373132 -0.992049  0.547567  0.315567 -0.916250  0.562286   \n150096  0.525108  0.370276 -0.992426  0.546147  0.315484 -0.917663  0.561741   \n150097  0.527792  0.370975 -1.054370  0.544327  0.313867 -0.981253  0.558664   \n150098  0.527792  0.370975 -1.054370  0.544327  0.313867 -0.981253  0.558664   \n150099  0.524986  0.361204 -1.097511  0.544687  0.304384 -1.024949  0.559115   \n\n              y3        z3        x4  ...       z51       x52       y52  \\\n0       0.367054 -1.074444  0.520200  ... -0.053524  0.399725  0.730864   \n1       0.352796 -0.929152  0.518936  ... -0.048000  0.398512  0.606266   \n2       0.352796 -0.929152  0.518936  ... -0.048000  0.398512  0.606266   \n3       0.363007 -0.816117  0.515710  ... -0.038509  0.395845  0.572608   \n4       0.355328 -0.869323  0.515255  ... -0.038847  0.392572  0.538630   \n...          ...       ...       ...  ...       ...       ...       ...   \n150095  0.317489 -0.916352  0.575725  ... -0.028968  0.291391  0.640639   \n150096  0.318271 -0.917825  0.575497  ... -0.037876  0.269125  0.701057   \n150097  0.314726 -0.981566  0.572358  ... -0.033339  0.254433  0.791060   \n150098  0.314726 -0.981566  0.572358  ... -0.033339  0.254433  0.791060   \n150099  0.306688 -1.025168  0.573416  ... -0.031130  0.237031  0.866545   \n\n             z52       x53       y53       z53       x54       y54       z54  \n0      -0.062620  0.427866  0.751528 -0.060393  0.447253  0.774449 -0.058090  \n1      -0.058852  0.428957  0.621372 -0.059092  0.449393  0.640706 -0.057821  \n2      -0.058852  0.428957  0.621372 -0.059092  0.449393  0.640706 -0.057821  \n3      -0.049951  0.427251  0.590068 -0.049887  0.448360  0.611298 -0.047701  \n4      -0.047879  0.424092  0.548410 -0.046750  0.444159  0.566794 -0.043640  \n...          ...       ...       ...       ...       ...       ...       ...  \n150095 -0.037794  0.303840  0.616979 -0.037350  0.316877  0.597338 -0.033791  \n150096 -0.056327  0.279851  0.691119 -0.060445  0.289750  0.684217 -0.059406  \n150097 -0.041410  0.265023  0.817268 -0.038859  0.269435  0.841274 -0.033614  \n150098 -0.041410  0.265023  0.817268 -0.038859  0.269435  0.841274 -0.033614  \n150099 -0.038810  0.246614  0.893922 -0.036005  0.250141  0.914375 -0.030636  \n\n[145455 rows x 162 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>x1</th>\n      <th>y1</th>\n      <th>z1</th>\n      <th>x2</th>\n      <th>y2</th>\n      <th>z2</th>\n      <th>x3</th>\n      <th>y3</th>\n      <th>z3</th>\n      <th>x4</th>\n      <th>...</th>\n      <th>z51</th>\n      <th>x52</th>\n      <th>y52</th>\n      <th>z52</th>\n      <th>x53</th>\n      <th>y53</th>\n      <th>z53</th>\n      <th>x54</th>\n      <th>y54</th>\n      <th>z54</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.469715</td>\n      <td>0.440847</td>\n      <td>-1.146045</td>\n      <td>0.492933</td>\n      <td>0.367618</td>\n      <td>-1.074119</td>\n      <td>0.506275</td>\n      <td>0.367054</td>\n      <td>-1.074444</td>\n      <td>0.520200</td>\n      <td>...</td>\n      <td>-0.053524</td>\n      <td>0.399725</td>\n      <td>0.730864</td>\n      <td>-0.062620</td>\n      <td>0.427866</td>\n      <td>0.751528</td>\n      <td>-0.060393</td>\n      <td>0.447253</td>\n      <td>0.774449</td>\n      <td>-0.058090</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.470880</td>\n      <td>0.431583</td>\n      <td>-1.010670</td>\n      <td>0.493463</td>\n      <td>0.355553</td>\n      <td>-0.928780</td>\n      <td>0.505930</td>\n      <td>0.352796</td>\n      <td>-0.929152</td>\n      <td>0.518936</td>\n      <td>...</td>\n      <td>-0.048000</td>\n      <td>0.398512</td>\n      <td>0.606266</td>\n      <td>-0.058852</td>\n      <td>0.428957</td>\n      <td>0.621372</td>\n      <td>-0.059092</td>\n      <td>0.449393</td>\n      <td>0.640706</td>\n      <td>-0.057821</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.470880</td>\n      <td>0.431583</td>\n      <td>-1.010670</td>\n      <td>0.493463</td>\n      <td>0.355553</td>\n      <td>-0.928780</td>\n      <td>0.505930</td>\n      <td>0.352796</td>\n      <td>-0.929152</td>\n      <td>0.518936</td>\n      <td>...</td>\n      <td>-0.048000</td>\n      <td>0.398512</td>\n      <td>0.606266</td>\n      <td>-0.058852</td>\n      <td>0.428957</td>\n      <td>0.621372</td>\n      <td>-0.059092</td>\n      <td>0.449393</td>\n      <td>0.640706</td>\n      <td>-0.057821</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.461313</td>\n      <td>0.441721</td>\n      <td>-0.895512</td>\n      <td>0.490067</td>\n      <td>0.364946</td>\n      <td>-0.815676</td>\n      <td>0.505128</td>\n      <td>0.363007</td>\n      <td>-0.816117</td>\n      <td>0.515710</td>\n      <td>...</td>\n      <td>-0.038509</td>\n      <td>0.395845</td>\n      <td>0.572608</td>\n      <td>-0.049951</td>\n      <td>0.427251</td>\n      <td>0.590068</td>\n      <td>-0.049887</td>\n      <td>0.448360</td>\n      <td>0.611298</td>\n      <td>-0.047701</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.462009</td>\n      <td>0.434323</td>\n      <td>-0.954978</td>\n      <td>0.490552</td>\n      <td>0.357484</td>\n      <td>-0.868968</td>\n      <td>0.504614</td>\n      <td>0.355328</td>\n      <td>-0.869323</td>\n      <td>0.515255</td>\n      <td>...</td>\n      <td>-0.038847</td>\n      <td>0.392572</td>\n      <td>0.538630</td>\n      <td>-0.047879</td>\n      <td>0.424092</td>\n      <td>0.548410</td>\n      <td>-0.046750</td>\n      <td>0.444159</td>\n      <td>0.566794</td>\n      <td>-0.043640</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>150095</th>\n      <td>0.528125</td>\n      <td>0.373132</td>\n      <td>-0.992049</td>\n      <td>0.547567</td>\n      <td>0.315567</td>\n      <td>-0.916250</td>\n      <td>0.562286</td>\n      <td>0.317489</td>\n      <td>-0.916352</td>\n      <td>0.575725</td>\n      <td>...</td>\n      <td>-0.028968</td>\n      <td>0.291391</td>\n      <td>0.640639</td>\n      <td>-0.037794</td>\n      <td>0.303840</td>\n      <td>0.616979</td>\n      <td>-0.037350</td>\n      <td>0.316877</td>\n      <td>0.597338</td>\n      <td>-0.033791</td>\n    </tr>\n    <tr>\n      <th>150096</th>\n      <td>0.525108</td>\n      <td>0.370276</td>\n      <td>-0.992426</td>\n      <td>0.546147</td>\n      <td>0.315484</td>\n      <td>-0.917663</td>\n      <td>0.561741</td>\n      <td>0.318271</td>\n      <td>-0.917825</td>\n      <td>0.575497</td>\n      <td>...</td>\n      <td>-0.037876</td>\n      <td>0.269125</td>\n      <td>0.701057</td>\n      <td>-0.056327</td>\n      <td>0.279851</td>\n      <td>0.691119</td>\n      <td>-0.060445</td>\n      <td>0.289750</td>\n      <td>0.684217</td>\n      <td>-0.059406</td>\n    </tr>\n    <tr>\n      <th>150097</th>\n      <td>0.527792</td>\n      <td>0.370975</td>\n      <td>-1.054370</td>\n      <td>0.544327</td>\n      <td>0.313867</td>\n      <td>-0.981253</td>\n      <td>0.558664</td>\n      <td>0.314726</td>\n      <td>-0.981566</td>\n      <td>0.572358</td>\n      <td>...</td>\n      <td>-0.033339</td>\n      <td>0.254433</td>\n      <td>0.791060</td>\n      <td>-0.041410</td>\n      <td>0.265023</td>\n      <td>0.817268</td>\n      <td>-0.038859</td>\n      <td>0.269435</td>\n      <td>0.841274</td>\n      <td>-0.033614</td>\n    </tr>\n    <tr>\n      <th>150098</th>\n      <td>0.527792</td>\n      <td>0.370975</td>\n      <td>-1.054370</td>\n      <td>0.544327</td>\n      <td>0.313867</td>\n      <td>-0.981253</td>\n      <td>0.558664</td>\n      <td>0.314726</td>\n      <td>-0.981566</td>\n      <td>0.572358</td>\n      <td>...</td>\n      <td>-0.033339</td>\n      <td>0.254433</td>\n      <td>0.791060</td>\n      <td>-0.041410</td>\n      <td>0.265023</td>\n      <td>0.817268</td>\n      <td>-0.038859</td>\n      <td>0.269435</td>\n      <td>0.841274</td>\n      <td>-0.033614</td>\n    </tr>\n    <tr>\n      <th>150099</th>\n      <td>0.524986</td>\n      <td>0.361204</td>\n      <td>-1.097511</td>\n      <td>0.544687</td>\n      <td>0.304384</td>\n      <td>-1.024949</td>\n      <td>0.559115</td>\n      <td>0.306688</td>\n      <td>-1.025168</td>\n      <td>0.573416</td>\n      <td>...</td>\n      <td>-0.031130</td>\n      <td>0.237031</td>\n      <td>0.866545</td>\n      <td>-0.038810</td>\n      <td>0.246614</td>\n      <td>0.893922</td>\n      <td>-0.036005</td>\n      <td>0.250141</td>\n      <td>0.914375</td>\n      <td>-0.030636</td>\n    </tr>\n  </tbody>\n</table>\n<p>145455 rows × 162 columns</p>\n</div>"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_feature"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "             x1        y1        z1        x2        y2        z2        x3  \\\n1      0.429909  0.299091 -1.033196  0.457929  0.241853 -0.964616  0.474237   \n2      0.429909  0.299091 -1.033196  0.457929  0.241853 -0.964616  0.474237   \n3      0.432813  0.310793 -1.206027  0.460014  0.253977 -1.139681  0.475536   \n4      0.437205  0.306630 -1.133030  0.462581  0.252750 -1.060267  0.477573   \n5      0.437205  0.306630 -1.133030  0.462581  0.252750 -1.060267  0.477573   \n...         ...       ...       ...       ...       ...       ...       ...   \n35230  0.511456  0.460191 -0.959940  0.534037  0.401124 -0.899052  0.548146   \n35231  0.501599  0.458881 -1.124302  0.526439  0.400657 -1.055216  0.540674   \n35232  0.505169  0.450338 -1.266487  0.532236  0.391213 -1.192186  0.547755   \n35233  0.518348  0.452888 -1.254290  0.540892  0.397112 -1.181628  0.555048   \n35234  0.522974  0.458728 -1.299674  0.544999  0.402066 -1.227341  0.558838   \n\n             y3        z3        x4  ...       z72       x73       y73  \\\n1      0.243988 -0.964898  0.489387  ... -0.015277  0.705914  0.929784   \n2      0.243988 -0.964898  0.489387  ... -0.015277  0.705914  0.929784   \n3      0.256214 -1.139858  0.490387  ... -0.025833  0.697252  0.873881   \n4      0.254981 -1.060502  0.491673  ... -0.021447  0.692508  0.823403   \n5      0.254981 -1.060502  0.491673  ... -0.021447  0.692508  0.823403   \n...         ...       ...       ...  ...       ...       ...       ...   \n35230  0.401731 -0.898836  0.559430  ... -0.039919  0.809364  0.820627   \n35231  0.401736 -1.055150  0.554994  ... -0.043934  0.785507  0.907059   \n35232  0.393168 -1.192205  0.561072  ... -0.037867  0.773673  0.957604   \n35233  0.398733 -1.181709  0.567229  ... -0.029353  0.762456  0.991850   \n35234  0.402731 -1.227251  0.571938  ... -0.022544  0.722687  1.041104   \n\n            z73       x74       y74       z74       x75       y75       z75  \n1     -0.020854  0.714973  0.895617 -0.020210  0.719473  0.867781 -0.019419  \n2     -0.020854  0.714973  0.895617 -0.020210  0.719473  0.867781 -0.019419  \n3     -0.033462  0.707033  0.841776 -0.032931  0.713368  0.814074 -0.031750  \n4     -0.029377  0.701794  0.792851 -0.029400  0.709057  0.765694 -0.028588  \n5     -0.029377  0.701794  0.792851 -0.029400  0.709057  0.765694 -0.028588  \n...         ...       ...       ...       ...       ...       ...       ...  \n35230 -0.052186  0.828242  0.795007 -0.057392  0.844519  0.771788 -0.060988  \n35231 -0.058207  0.802646  0.886843 -0.061276  0.817798  0.866778 -0.062948  \n35232 -0.047840  0.788576  0.940628 -0.046659  0.799739  0.923667 -0.045932  \n35233 -0.037508  0.779295  0.966001 -0.036288  0.792470  0.945838 -0.035624  \n35234 -0.026217  0.734203  1.022373 -0.022036  0.742804  1.011384 -0.020418  \n\n[29011 rows x 225 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>x1</th>\n      <th>y1</th>\n      <th>z1</th>\n      <th>x2</th>\n      <th>y2</th>\n      <th>z2</th>\n      <th>x3</th>\n      <th>y3</th>\n      <th>z3</th>\n      <th>x4</th>\n      <th>...</th>\n      <th>z72</th>\n      <th>x73</th>\n      <th>y73</th>\n      <th>z73</th>\n      <th>x74</th>\n      <th>y74</th>\n      <th>z74</th>\n      <th>x75</th>\n      <th>y75</th>\n      <th>z75</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>0.429909</td>\n      <td>0.299091</td>\n      <td>-1.033196</td>\n      <td>0.457929</td>\n      <td>0.241853</td>\n      <td>-0.964616</td>\n      <td>0.474237</td>\n      <td>0.243988</td>\n      <td>-0.964898</td>\n      <td>0.489387</td>\n      <td>...</td>\n      <td>-0.015277</td>\n      <td>0.705914</td>\n      <td>0.929784</td>\n      <td>-0.020854</td>\n      <td>0.714973</td>\n      <td>0.895617</td>\n      <td>-0.020210</td>\n      <td>0.719473</td>\n      <td>0.867781</td>\n      <td>-0.019419</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.429909</td>\n      <td>0.299091</td>\n      <td>-1.033196</td>\n      <td>0.457929</td>\n      <td>0.241853</td>\n      <td>-0.964616</td>\n      <td>0.474237</td>\n      <td>0.243988</td>\n      <td>-0.964898</td>\n      <td>0.489387</td>\n      <td>...</td>\n      <td>-0.015277</td>\n      <td>0.705914</td>\n      <td>0.929784</td>\n      <td>-0.020854</td>\n      <td>0.714973</td>\n      <td>0.895617</td>\n      <td>-0.020210</td>\n      <td>0.719473</td>\n      <td>0.867781</td>\n      <td>-0.019419</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.432813</td>\n      <td>0.310793</td>\n      <td>-1.206027</td>\n      <td>0.460014</td>\n      <td>0.253977</td>\n      <td>-1.139681</td>\n      <td>0.475536</td>\n      <td>0.256214</td>\n      <td>-1.139858</td>\n      <td>0.490387</td>\n      <td>...</td>\n      <td>-0.025833</td>\n      <td>0.697252</td>\n      <td>0.873881</td>\n      <td>-0.033462</td>\n      <td>0.707033</td>\n      <td>0.841776</td>\n      <td>-0.032931</td>\n      <td>0.713368</td>\n      <td>0.814074</td>\n      <td>-0.031750</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.437205</td>\n      <td>0.306630</td>\n      <td>-1.133030</td>\n      <td>0.462581</td>\n      <td>0.252750</td>\n      <td>-1.060267</td>\n      <td>0.477573</td>\n      <td>0.254981</td>\n      <td>-1.060502</td>\n      <td>0.491673</td>\n      <td>...</td>\n      <td>-0.021447</td>\n      <td>0.692508</td>\n      <td>0.823403</td>\n      <td>-0.029377</td>\n      <td>0.701794</td>\n      <td>0.792851</td>\n      <td>-0.029400</td>\n      <td>0.709057</td>\n      <td>0.765694</td>\n      <td>-0.028588</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0.437205</td>\n      <td>0.306630</td>\n      <td>-1.133030</td>\n      <td>0.462581</td>\n      <td>0.252750</td>\n      <td>-1.060267</td>\n      <td>0.477573</td>\n      <td>0.254981</td>\n      <td>-1.060502</td>\n      <td>0.491673</td>\n      <td>...</td>\n      <td>-0.021447</td>\n      <td>0.692508</td>\n      <td>0.823403</td>\n      <td>-0.029377</td>\n      <td>0.701794</td>\n      <td>0.792851</td>\n      <td>-0.029400</td>\n      <td>0.709057</td>\n      <td>0.765694</td>\n      <td>-0.028588</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>35230</th>\n      <td>0.511456</td>\n      <td>0.460191</td>\n      <td>-0.959940</td>\n      <td>0.534037</td>\n      <td>0.401124</td>\n      <td>-0.899052</td>\n      <td>0.548146</td>\n      <td>0.401731</td>\n      <td>-0.898836</td>\n      <td>0.559430</td>\n      <td>...</td>\n      <td>-0.039919</td>\n      <td>0.809364</td>\n      <td>0.820627</td>\n      <td>-0.052186</td>\n      <td>0.828242</td>\n      <td>0.795007</td>\n      <td>-0.057392</td>\n      <td>0.844519</td>\n      <td>0.771788</td>\n      <td>-0.060988</td>\n    </tr>\n    <tr>\n      <th>35231</th>\n      <td>0.501599</td>\n      <td>0.458881</td>\n      <td>-1.124302</td>\n      <td>0.526439</td>\n      <td>0.400657</td>\n      <td>-1.055216</td>\n      <td>0.540674</td>\n      <td>0.401736</td>\n      <td>-1.055150</td>\n      <td>0.554994</td>\n      <td>...</td>\n      <td>-0.043934</td>\n      <td>0.785507</td>\n      <td>0.907059</td>\n      <td>-0.058207</td>\n      <td>0.802646</td>\n      <td>0.886843</td>\n      <td>-0.061276</td>\n      <td>0.817798</td>\n      <td>0.866778</td>\n      <td>-0.062948</td>\n    </tr>\n    <tr>\n      <th>35232</th>\n      <td>0.505169</td>\n      <td>0.450338</td>\n      <td>-1.266487</td>\n      <td>0.532236</td>\n      <td>0.391213</td>\n      <td>-1.192186</td>\n      <td>0.547755</td>\n      <td>0.393168</td>\n      <td>-1.192205</td>\n      <td>0.561072</td>\n      <td>...</td>\n      <td>-0.037867</td>\n      <td>0.773673</td>\n      <td>0.957604</td>\n      <td>-0.047840</td>\n      <td>0.788576</td>\n      <td>0.940628</td>\n      <td>-0.046659</td>\n      <td>0.799739</td>\n      <td>0.923667</td>\n      <td>-0.045932</td>\n    </tr>\n    <tr>\n      <th>35233</th>\n      <td>0.518348</td>\n      <td>0.452888</td>\n      <td>-1.254290</td>\n      <td>0.540892</td>\n      <td>0.397112</td>\n      <td>-1.181628</td>\n      <td>0.555048</td>\n      <td>0.398733</td>\n      <td>-1.181709</td>\n      <td>0.567229</td>\n      <td>...</td>\n      <td>-0.029353</td>\n      <td>0.762456</td>\n      <td>0.991850</td>\n      <td>-0.037508</td>\n      <td>0.779295</td>\n      <td>0.966001</td>\n      <td>-0.036288</td>\n      <td>0.792470</td>\n      <td>0.945838</td>\n      <td>-0.035624</td>\n    </tr>\n    <tr>\n      <th>35234</th>\n      <td>0.522974</td>\n      <td>0.458728</td>\n      <td>-1.299674</td>\n      <td>0.544999</td>\n      <td>0.402066</td>\n      <td>-1.227341</td>\n      <td>0.558838</td>\n      <td>0.402731</td>\n      <td>-1.227251</td>\n      <td>0.571938</td>\n      <td>...</td>\n      <td>-0.022544</td>\n      <td>0.722687</td>\n      <td>1.041104</td>\n      <td>-0.026217</td>\n      <td>0.734203</td>\n      <td>1.022373</td>\n      <td>-0.022036</td>\n      <td>0.742804</td>\n      <td>1.011384</td>\n      <td>-0.020418</td>\n    </tr>\n  </tbody>\n</table>\n<p>29011 rows × 225 columns</p>\n</div>"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "two_feature"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "data": {
      "text/plain": "0          0\n1          0\n2          0\n3          0\n4          0\n          ..\n150095    ไอ\n150096    ไอ\n150097    ไอ\n150098    ไอ\n150099    ไอ\nName: class, Length: 145455, dtype: object"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_label"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "data": {
      "text/plain": "1               อ่\n2               อ่\n3               อ่\n4               อ่\n5               อ่\n           ...    \n35230    ไม้ไต่คู้\n35231    ไม้ไต่คู้\n35232    ไม้ไต่คู้\n35233    ไม้ไต่คู้\n35234    ไม้ไต่คู้\nName: class, Length: 29011, dtype: object"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "two_label"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One_Feature = (145455, 162)  ; One_Label = (145455,)\n",
      "{'ฌ', '4', 'น', 'ศ', 'ษ', '1,000', '1,000,000', 'ก', 'ซ', '100,000', 'ฒ', 'ถ', 'ร', '100', '6', 'ณ', '30', 'ฝ', 'ฮ', 'อื(คือ)', '2', '8', 'ท', 'ล', '90', 'อิ', 'ช', '3', 'ง', 'ภ', 'ข', 'ธ', 'ฬ', '10', '10,000', 'ว', '7', '60', 'ญ', 'ไอ', 'ฐ', '40', 'ผ', '1', 'ใอ', 'จ', 'โอ', 'ด', 'ต', 'พ', '0', '20', '9', 'ฎ', 'ส', 'อ', '5', '80', 'ฑ', 'อึ(นึก)', 'ค', '70', 'ย', 'ห', '50', 'บ', 'ฆ', 'ม', 'ฉ', 'ฟ', 'อี', 'ป', 'ฏ'}\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Two_Feature = (29011, 225)  ; Two_Label = (29011,)\n",
      "{'ฌ', '4', 'น', 'ศ', 'ษ', '1,000', '1,000,000', 'ก', 'ซ', '100,000', 'ฒ', 'ถ', 'ร', '100', '6', 'ณ', '30', 'ฝ', 'ฮ', 'อื(คือ)', '2', '8', 'ท', 'ล', '90', 'อิ', 'ช', '3', 'ง', 'ภ', 'ข', 'ธ', 'ฬ', '10', '10,000', 'ว', '7', '60', 'ญ', 'ไอ', 'ฐ', '40', 'ผ', '1', 'ใอ', 'จ', 'โอ', 'ด', 'ต', 'พ', '0', '20', '9', 'ฎ', 'ส', 'อ', '5', '80', 'ฑ', 'อึ(นึก)', 'ค', '70', 'ย', 'ห', '50', 'บ', 'ฆ', 'ม', 'ฉ', 'ฟ', 'อี', 'ป', 'ฏ'}\n"
     ]
    }
   ],
   "source": [
    "print(f'One_Feature = {one_feature.shape}  ; One_Label = {one_label.shape}')\n",
    "print(set(one_label))\n",
    "print('-' * 100)\n",
    "print(f'Two_Feature = {two_feature.shape}  ; Two_Label = {two_label.shape}')\n",
    "print(set(one_label))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One Hand =  (87273, 162) (58182, 162) (87273,) (58182,)\n",
      "Two Hand =  (17406, 225) (11605, 225) (17406,) (11605,)\n"
     ]
    }
   ],
   "source": [
    "one_x_train, one_x_test, one_y_train, one_y_test = train_test_split(one_feature, one_label,test_size=0.4, shuffle= True, random_state= 42)\n",
    "two_x_train, two_x_test, two_y_train, two_y_test = train_test_split(two_feature, two_label,test_size=0.4, shuffle= True, random_state= 42)\n",
    "\n",
    "print('One Hand = ',one_x_train.shape, one_x_test.shape, one_y_train.shape, one_y_test.shape)\n",
    "print('Two Hand = ', two_x_train.shape, two_x_test.shape, two_y_train.shape, two_y_test.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "one_x_train /= 255.0\n",
    "one_x_test /= 255.0\n",
    "\n",
    "two_x_train /= 255.0\n",
    "two_x_test /= 255.0"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "one_x_train = (87273, 162), one_x_val = (29091, 162), one_x_test = (29091, 162)\n",
      "one_y_train = (87273,), one_y_val = (29091,), one_y_test = (29091,)\n"
     ]
    }
   ],
   "source": [
    "one_x_val, one_x_test, one_y_val, one_y_test = train_test_split(one_x_test, one_y_test, test_size=0.5, shuffle=True, random_state=42)\n",
    "print('one_x_train = {}, one_x_val = {}, one_x_test = {}'.format(one_x_train.shape, one_x_val.shape, one_x_test.shape))\n",
    "print('one_y_train = {}, one_y_val = {}, one_y_test = {}'.format(one_y_train.shape, one_y_val.shape, one_y_test.shape))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "two_x_train = (17406, 225), two_x_val = (5802, 225), two_x_test = (5803, 225)\n",
      "two_y_train = (17406,), two_y_val = (5802,), two_y_test = (5803,)\n"
     ]
    }
   ],
   "source": [
    "two_x_val, two_x_test, two_y_val, two_y_test = train_test_split(two_x_test, two_y_test, test_size=0.5, shuffle=True, random_state=42)\n",
    "print('two_x_train = {}, two_x_val = {}, two_x_test = {}'.format(two_x_train.shape, two_x_val.shape, two_x_test.shape))\n",
    "print('two_y_train = {}, two_y_val = {}, two_y_test = {}'.format(two_y_train.shape, two_y_val.shape, two_y_test.shape))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "one_x_train = (87273, 162), one_x_val = (29091, 162), one_x_test = (29091, 162)\n",
      "one_y_train = (87273,), one_y_val = (29091,), one_y_test = (29091,)\n",
      "one_x_val_class= (87273, 73), one_y_val_class = (29091, 73)\n",
      "{'ษ', '4', 'ฌ', 'น', 'ศ', '1,000', 'ก', 'ฒ', 'ซ', '100,000', 'ถ', 'ร', '1,000,000', '100', '6', 'ณ', '30', 'ฮ', 'อื(คือ)', 'ฝ', '8', 'ท', '2', '90', 'อิ', 'ภ', '3', 'ง', 'ฟ', 'ช', 'ข', 'ธ', 'ฬ', '10', '10,000', 'ว', '7', '60', 'ญ', 'ผ', '40', 'ฐ', '1', 'ใอ', 'โอ', 'จ', 'พ', 'ต', 'ด', '0', '20', '9', 'ฎ', 'อ', 'ส', 'อึ(นึก)', '80', 'ฑ', '5', 'ค', '70', 'ป', 'ห', 'ย', '50', 'ม', 'ฆ', 'บ', 'ฉ', 'ไอ', 'อี', 'ล', 'ฏ'}\n"
     ]
    }
   ],
   "source": [
    "# One-Hot One hand encoding\n",
    "one_x_val_class = pd.get_dummies(one_y_train).values\n",
    "one_y_val_class = pd.get_dummies(one_y_val).values\n",
    "print('one_x_train = {}, one_x_val = {}, one_x_test = {}'.format(one_x_train.shape, one_x_val.shape, one_x_test.shape))\n",
    "print('one_y_train = {}, one_y_val = {}, one_y_test = {}'.format(one_y_train.shape, one_y_val.shape, one_y_test.shape))\n",
    "print('one_x_val_class= {}, one_y_val_class = {}'.format(one_x_val_class.shape, one_y_val_class.shape))\n",
    "print(set(one_y_val))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "two_x_train = (17406, 225), two_x_val = (5802, 225), two_x_test = (5803, 225)\n",
      "two_y_train = (17406,), two_y_val = (5802,), two_y_test = (5803,)\n",
      "two_x_val_class = (17406, 16), two_y_val_class = (5802, 16)\n",
      "{'ทัณฑฆาต', 'อะ', 'อำ', 'อู', 'ฤ', 'อ๋', 'อุ', 'เอ', 'แอ', 'ไม้ไต่คู้', 'อา', 'ฯ', 'อ้', 'อ๊', 'ไม้หันอากาศ', 'อ่'}\n"
     ]
    }
   ],
   "source": [
    "# One-Hot Two hand encoding\n",
    "two_x_val_class = pd.get_dummies(two_y_train).values\n",
    "two_y_val_class = pd.get_dummies(two_y_val).values\n",
    "print('two_x_train = {}, two_x_val = {}, two_x_test = {}'.format(two_x_train.shape, two_x_val.shape, two_x_test.shape))\n",
    "print('two_y_train = {}, two_y_val = {}, two_y_test = {}'.format(two_y_train.shape, two_y_val.shape, two_y_test.shape))\n",
    "print('two_x_val_class = {}, two_y_val_class = {}'.format(two_x_val_class.shape, two_y_val_class.shape))\n",
    "print(set(two_y_val))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "data": {
      "text/plain": "162"
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_x_train.shape[1]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, 162, 256)          264192    \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 162, 128)          197120    \n",
      "                                                                 \n",
      " lstm_2 (LSTM)               (None, 64)                49408     \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 64)                0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               33280     \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 512)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 84)                43092     \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 84)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 73)                6205      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 593,297\n",
      "Trainable params: 593,297\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def onehand_LSTM():\n",
    "    model = Sequential()\n",
    "\n",
    "    # model.add(LSTM(units = 32, input_shape=(step, 1), activation= 'tanh'))\n",
    "\n",
    "    model.add(LSTM(units = 256, input_shape=(one_x_train.shape[1], 1), activation= 'tanh', return_sequences= True))\n",
    "    model.add(LSTM(units = 128, activation='tanh', return_sequences=True))\n",
    "    model.add(LSTM(units= 64, activation= 'tanh'))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(units = 512, activation = 'tanh'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(units = 84, activation = 'tanh'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(units= one_x_val_class.shape[1], activation= 'softmax'))\n",
    "    model.compile(optimizer= 'adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "one_model = onehand_LSTM()\n",
    "one_model.build()\n",
    "one_model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "data": {
      "text/plain": "             x1        y1        z1        x2        y2        z2        x3  \\\n6581   0.001774  0.001207 -0.004308  0.001872  0.000995 -0.004016  0.001931   \n30575  0.001950  0.001147 -0.003209  0.002025  0.000940 -0.002942  0.002081   \n9586   0.001788  0.001353 -0.002633  0.001870  0.001149 -0.002433  0.001925   \n13475  0.001840  0.001349 -0.002223  0.001921  0.001086 -0.001951  0.001977   \n15845  0.002041  0.001832 -0.004481  0.002105  0.001592 -0.004224  0.002154   \n...         ...       ...       ...       ...       ...       ...       ...   \n26270  0.001829  0.001134 -0.002652  0.001921  0.000939 -0.002402  0.001984   \n6933   0.001876  0.001186 -0.002609  0.001934  0.000946 -0.002377  0.001982   \n1148   0.001712  0.001242 -0.004085  0.001798  0.001025 -0.003793  0.001856   \n19388  0.001840  0.001229 -0.002919  0.001919  0.001029 -0.002655  0.001975   \n28756  0.001926  0.001358 -0.004936  0.002019  0.001118 -0.004668  0.002081   \n\n             y3        z3        x4  ...       z72       x73       y73  \\\n6581   0.001002 -0.004017  0.001983  ... -0.000104  0.002619  0.003002   \n30575  0.000940 -0.002943  0.002127  ... -0.000101  0.002860  0.002580   \n9586   0.001146 -0.002434  0.001977  ... -0.000140  0.002637  0.002717   \n13475  0.001084 -0.001951  0.002031  ... -0.000088  0.003484  0.002490   \n15845  0.001588 -0.004223  0.002198  ... -0.000117  0.003115  0.002806   \n...         ...       ...       ...  ...       ...       ...       ...   \n26270  0.000943 -0.002402  0.002038  ... -0.000063  0.002882  0.002412   \n6933   0.000942 -0.002377  0.002026  ... -0.000150  0.002702  0.002221   \n1148   0.001023 -0.003793  0.001904  ... -0.000122  0.003370  0.002510   \n19388  0.001036 -0.002655  0.002024  ... -0.000115  0.003078  0.002875   \n28756  0.001118 -0.004667  0.002137  ... -0.000095  0.002925  0.002823   \n\n            z73       x74       y74       z74       x75       y75       z75  \n6581  -0.000161  0.002606  0.002990 -0.000176  0.002591  0.002997 -0.000185  \n30575 -0.000143  0.002897  0.002475 -0.000163  0.002925  0.002377 -0.000177  \n9586  -0.000193  0.002689  0.002609 -0.000208  0.002733  0.002503 -0.000217  \n13475 -0.000116  0.003532  0.002391 -0.000124  0.003575  0.002298 -0.000130  \n15845 -0.000165  0.003172  0.002691 -0.000192  0.003219  0.002584 -0.000207  \n...         ...       ...       ...       ...       ...       ...       ...  \n26270 -0.000108  0.002853  0.002431 -0.000128  0.002817  0.002443 -0.000143  \n6933  -0.000210  0.002666  0.002197 -0.000226  0.002624  0.002186 -0.000236  \n1148  -0.000170  0.003408  0.002394 -0.000188  0.003438  0.002286 -0.000198  \n19388 -0.000138  0.003131  0.002783 -0.000149  0.003179  0.002696 -0.000158  \n28756 -0.000137  0.002964  0.002692 -0.000154  0.002992  0.002572 -0.000163  \n\n[17406 rows x 225 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>x1</th>\n      <th>y1</th>\n      <th>z1</th>\n      <th>x2</th>\n      <th>y2</th>\n      <th>z2</th>\n      <th>x3</th>\n      <th>y3</th>\n      <th>z3</th>\n      <th>x4</th>\n      <th>...</th>\n      <th>z72</th>\n      <th>x73</th>\n      <th>y73</th>\n      <th>z73</th>\n      <th>x74</th>\n      <th>y74</th>\n      <th>z74</th>\n      <th>x75</th>\n      <th>y75</th>\n      <th>z75</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>6581</th>\n      <td>0.001774</td>\n      <td>0.001207</td>\n      <td>-0.004308</td>\n      <td>0.001872</td>\n      <td>0.000995</td>\n      <td>-0.004016</td>\n      <td>0.001931</td>\n      <td>0.001002</td>\n      <td>-0.004017</td>\n      <td>0.001983</td>\n      <td>...</td>\n      <td>-0.000104</td>\n      <td>0.002619</td>\n      <td>0.003002</td>\n      <td>-0.000161</td>\n      <td>0.002606</td>\n      <td>0.002990</td>\n      <td>-0.000176</td>\n      <td>0.002591</td>\n      <td>0.002997</td>\n      <td>-0.000185</td>\n    </tr>\n    <tr>\n      <th>30575</th>\n      <td>0.001950</td>\n      <td>0.001147</td>\n      <td>-0.003209</td>\n      <td>0.002025</td>\n      <td>0.000940</td>\n      <td>-0.002942</td>\n      <td>0.002081</td>\n      <td>0.000940</td>\n      <td>-0.002943</td>\n      <td>0.002127</td>\n      <td>...</td>\n      <td>-0.000101</td>\n      <td>0.002860</td>\n      <td>0.002580</td>\n      <td>-0.000143</td>\n      <td>0.002897</td>\n      <td>0.002475</td>\n      <td>-0.000163</td>\n      <td>0.002925</td>\n      <td>0.002377</td>\n      <td>-0.000177</td>\n    </tr>\n    <tr>\n      <th>9586</th>\n      <td>0.001788</td>\n      <td>0.001353</td>\n      <td>-0.002633</td>\n      <td>0.001870</td>\n      <td>0.001149</td>\n      <td>-0.002433</td>\n      <td>0.001925</td>\n      <td>0.001146</td>\n      <td>-0.002434</td>\n      <td>0.001977</td>\n      <td>...</td>\n      <td>-0.000140</td>\n      <td>0.002637</td>\n      <td>0.002717</td>\n      <td>-0.000193</td>\n      <td>0.002689</td>\n      <td>0.002609</td>\n      <td>-0.000208</td>\n      <td>0.002733</td>\n      <td>0.002503</td>\n      <td>-0.000217</td>\n    </tr>\n    <tr>\n      <th>13475</th>\n      <td>0.001840</td>\n      <td>0.001349</td>\n      <td>-0.002223</td>\n      <td>0.001921</td>\n      <td>0.001086</td>\n      <td>-0.001951</td>\n      <td>0.001977</td>\n      <td>0.001084</td>\n      <td>-0.001951</td>\n      <td>0.002031</td>\n      <td>...</td>\n      <td>-0.000088</td>\n      <td>0.003484</td>\n      <td>0.002490</td>\n      <td>-0.000116</td>\n      <td>0.003532</td>\n      <td>0.002391</td>\n      <td>-0.000124</td>\n      <td>0.003575</td>\n      <td>0.002298</td>\n      <td>-0.000130</td>\n    </tr>\n    <tr>\n      <th>15845</th>\n      <td>0.002041</td>\n      <td>0.001832</td>\n      <td>-0.004481</td>\n      <td>0.002105</td>\n      <td>0.001592</td>\n      <td>-0.004224</td>\n      <td>0.002154</td>\n      <td>0.001588</td>\n      <td>-0.004223</td>\n      <td>0.002198</td>\n      <td>...</td>\n      <td>-0.000117</td>\n      <td>0.003115</td>\n      <td>0.002806</td>\n      <td>-0.000165</td>\n      <td>0.003172</td>\n      <td>0.002691</td>\n      <td>-0.000192</td>\n      <td>0.003219</td>\n      <td>0.002584</td>\n      <td>-0.000207</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>26270</th>\n      <td>0.001829</td>\n      <td>0.001134</td>\n      <td>-0.002652</td>\n      <td>0.001921</td>\n      <td>0.000939</td>\n      <td>-0.002402</td>\n      <td>0.001984</td>\n      <td>0.000943</td>\n      <td>-0.002402</td>\n      <td>0.002038</td>\n      <td>...</td>\n      <td>-0.000063</td>\n      <td>0.002882</td>\n      <td>0.002412</td>\n      <td>-0.000108</td>\n      <td>0.002853</td>\n      <td>0.002431</td>\n      <td>-0.000128</td>\n      <td>0.002817</td>\n      <td>0.002443</td>\n      <td>-0.000143</td>\n    </tr>\n    <tr>\n      <th>6933</th>\n      <td>0.001876</td>\n      <td>0.001186</td>\n      <td>-0.002609</td>\n      <td>0.001934</td>\n      <td>0.000946</td>\n      <td>-0.002377</td>\n      <td>0.001982</td>\n      <td>0.000942</td>\n      <td>-0.002377</td>\n      <td>0.002026</td>\n      <td>...</td>\n      <td>-0.000150</td>\n      <td>0.002702</td>\n      <td>0.002221</td>\n      <td>-0.000210</td>\n      <td>0.002666</td>\n      <td>0.002197</td>\n      <td>-0.000226</td>\n      <td>0.002624</td>\n      <td>0.002186</td>\n      <td>-0.000236</td>\n    </tr>\n    <tr>\n      <th>1148</th>\n      <td>0.001712</td>\n      <td>0.001242</td>\n      <td>-0.004085</td>\n      <td>0.001798</td>\n      <td>0.001025</td>\n      <td>-0.003793</td>\n      <td>0.001856</td>\n      <td>0.001023</td>\n      <td>-0.003793</td>\n      <td>0.001904</td>\n      <td>...</td>\n      <td>-0.000122</td>\n      <td>0.003370</td>\n      <td>0.002510</td>\n      <td>-0.000170</td>\n      <td>0.003408</td>\n      <td>0.002394</td>\n      <td>-0.000188</td>\n      <td>0.003438</td>\n      <td>0.002286</td>\n      <td>-0.000198</td>\n    </tr>\n    <tr>\n      <th>19388</th>\n      <td>0.001840</td>\n      <td>0.001229</td>\n      <td>-0.002919</td>\n      <td>0.001919</td>\n      <td>0.001029</td>\n      <td>-0.002655</td>\n      <td>0.001975</td>\n      <td>0.001036</td>\n      <td>-0.002655</td>\n      <td>0.002024</td>\n      <td>...</td>\n      <td>-0.000115</td>\n      <td>0.003078</td>\n      <td>0.002875</td>\n      <td>-0.000138</td>\n      <td>0.003131</td>\n      <td>0.002783</td>\n      <td>-0.000149</td>\n      <td>0.003179</td>\n      <td>0.002696</td>\n      <td>-0.000158</td>\n    </tr>\n    <tr>\n      <th>28756</th>\n      <td>0.001926</td>\n      <td>0.001358</td>\n      <td>-0.004936</td>\n      <td>0.002019</td>\n      <td>0.001118</td>\n      <td>-0.004668</td>\n      <td>0.002081</td>\n      <td>0.001118</td>\n      <td>-0.004667</td>\n      <td>0.002137</td>\n      <td>...</td>\n      <td>-0.000095</td>\n      <td>0.002925</td>\n      <td>0.002823</td>\n      <td>-0.000137</td>\n      <td>0.002964</td>\n      <td>0.002692</td>\n      <td>-0.000154</td>\n      <td>0.002992</td>\n      <td>0.002572</td>\n      <td>-0.000163</td>\n    </tr>\n  </tbody>\n</table>\n<p>17406 rows × 225 columns</p>\n</div>"
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "two_x_train"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "data": {
      "text/plain": "225"
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "two_x_train.shape[1]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_3 (LSTM)               (None, 225, 256)          264192    \n",
      "                                                                 \n",
      " lstm_4 (LSTM)               (None, 225, 128)          197120    \n",
      "                                                                 \n",
      " lstm_5 (LSTM)               (None, 128)               131584    \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 128)               16512     \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 84)                10836     \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 16)                1360      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 621,604\n",
      "Trainable params: 621,604\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def twohand_LSTM():\n",
    "    model = Sequential()\n",
    "\n",
    "    # model.add(LSTM(units = 32, input_shape=(step, 1), activation= 'tanh'))\n",
    "\n",
    "    model.add(LSTM(units = 256, input_shape=(two_x_train.shape[1], 1), activation= 'tanh', return_sequences= True))\n",
    "    model.add(LSTM(units = 128, activation='tanh', return_sequences=True))\n",
    "    model.add(LSTM(units= 128, activation= 'tanh'))\n",
    "\n",
    "    # model.add(Flatten())\n",
    "    model.add(Dense(units = 128, activation = 'tanh'))\n",
    "    #model.add(Dropout(0.2))\n",
    "    model.add(Dense(units = 84, activation = 'tanh'))\n",
    "    #model.add(Dropout(0.2))\n",
    "    model.add(Dense(units= 16, activation= 'softmax'))\n",
    "    model.compile(optimizer= 'adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "two_model = twohand_LSTM()\n",
    "two_model.build()\n",
    "two_model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "data": {
      "text/plain": "x1     0.001774\ny1     0.001207\nz1    -0.004308\nx2     0.001872\ny2     0.000995\n         ...   \ny74    0.002990\nz74   -0.000176\nx75    0.002591\ny75    0.002997\nz75   -0.000185\nName: 6581, Length: 225, dtype: float64"
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "two_x_train.iloc[0]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [],
   "source": [
    "# DataGenerator\n",
    "class DataGenerator(Sequence):\n",
    "    def __init__(self, x_set, y_set, batch_size):\n",
    "        self.x, self.y = x_set, y_set\n",
    "        self.batch_size = batch_size\n",
    "        self.x = self.x[:len(x_set) // batch_size * batch_size]\n",
    "        self.y = self.y[:len(y_set) // batch_size * batch_size]\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.x) / float(self.batch_size)))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        batch_x = self.x[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        batch_y = self.y[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        clamp = min(len(batch_x),len(batch_y))\n",
    "        batch_x = batch_x[:clamp]\n",
    "        batch_y = batch_y[:clamp]\n",
    "        # print(len(batch_x))\n",
    "        # print(len(batch_x))\n",
    "        # print('-'*60)\n",
    "        return batch_x, batch_y\n",
    "\n",
    "\n",
    "one_train_gen = DataGenerator(one_x_train, one_x_val_class, 8)\n",
    "one_test_gen = DataGenerator(one_x_val, one_y_val_class, 8)\n",
    "\n",
    "two_train_gen = DataGenerator(two_x_train, two_x_val_class, 4)\n",
    "two_test_gen = DataGenerator(two_x_test, two_y_val_class, 4)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       ทัณฑฆาต  ฤ  อะ  อา  อำ  อุ  อู  อ่  อ้  อ๊  อ๋  ฯ  เอ  แอ  ไม้หันอากาศ  \\\n",
      "29250        0  0   0   0   0   0   0   0   0   0   0  0   0   1            0   \n",
      "27191        0  0   0   0   0   0   0   0   0   0   0  0   1   0            0   \n",
      "28718        0  0   0   0   0   0   0   0   0   0   0  0   0   1            0   \n",
      "32853        0  0   0   0   0   0   0   0   0   0   0  0   0   0            1   \n",
      "14300        0  0   1   0   0   0   0   0   0   0   0  0   0   0            0   \n",
      "13133        0  0   1   0   0   0   0   0   0   0   0  0   0   0            0   \n",
      "25076        0  0   0   0   0   0   0   0   0   0   0  1   0   0            0   \n",
      "6968         0  0   0   0   0   0   0   0   0   0   1  0   0   0            0   \n",
      "19482        0  0   0   0   1   0   0   0   0   0   0  0   0   0            0   \n",
      "8475         1  0   0   0   0   0   0   0   0   0   0  0   0   0            0   \n",
      "4909         0  0   0   0   0   0   0   0   0   1   0  0   0   0            0   \n",
      "30104        0  0   0   0   0   0   0   0   0   0   0  0   0   1            0   \n",
      "26547        0  0   0   0   0   0   0   0   0   0   0  0   1   0            0   \n",
      "26125        0  0   0   0   0   0   0   0   0   0   0  1   0   0            0   \n",
      "11452        0  1   0   0   0   0   0   0   0   0   0  0   0   0            0   \n",
      "16515        0  0   0   1   0   0   0   0   0   0   0  0   0   0            0   \n",
      "23810        0  0   0   0   0   0   1   0   0   0   0  0   0   0            0   \n",
      "12929        0  1   0   0   0   0   0   0   0   0   0  0   0   0            0   \n",
      "3811         0  0   0   0   0   0   0   0   1   0   0  0   0   0            0   \n",
      "15425        0  0   0   1   0   0   0   0   0   0   0  0   0   0            0   \n",
      "\n",
      "       ไม้ไต่คู้  \n",
      "29250          0  \n",
      "27191          0  \n",
      "28718          0  \n",
      "32853          0  \n",
      "14300          0  \n",
      "13133          0  \n",
      "25076          0  \n",
      "6968           0  \n",
      "19482          0  \n",
      "8475           0  \n",
      "4909           0  \n",
      "30104          0  \n",
      "26547          0  \n",
      "26125          0  \n",
      "11452          0  \n",
      "16515          0  \n",
      "23810          0  \n",
      "12929          0  \n",
      "3811           0  \n",
      "15425          0  \n",
      "(17406, 16)\n",
      "(5803, 16)\n"
     ]
    }
   ],
   "source": [
    "two_y_train_1h = pd.get_dummies(two_y_train) # One hot format\n",
    "two_y_test_1h = pd.get_dummies(two_y_test)\n",
    "print(two_y_test_1h.head(20))\n",
    "print(two_y_train_1h.shape)\n",
    "print(two_y_test_1h.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "870/871 [============================>.] - ETA: 0s - loss: 2.7744 - accuracy: 0.0674\n",
      "Epoch 1: val_accuracy improved from -inf to 0.06462, saving model to OneHand.h5\n",
      "871/871 [==============================] - 40s 42ms/step - loss: 2.7744 - accuracy: 0.0674 - val_loss: 2.7710 - val_accuracy: 0.0646\n",
      "Epoch 2/100\n",
      "870/871 [============================>.] - ETA: 0s - loss: 2.7725 - accuracy: 0.0672\n",
      "Epoch 2: val_accuracy improved from 0.06462 to 0.06692, saving model to OneHand.h5\n",
      "871/871 [==============================] - 38s 43ms/step - loss: 2.7725 - accuracy: 0.0672 - val_loss: 2.7719 - val_accuracy: 0.0669\n",
      "Epoch 3/100\n",
      "871/871 [==============================] - ETA: 0s - loss: 2.7725 - accuracy: 0.0671\n",
      "Epoch 3: val_accuracy improved from 0.06692 to 0.06835, saving model to OneHand.h5\n",
      "871/871 [==============================] - 36s 41ms/step - loss: 2.7725 - accuracy: 0.0671 - val_loss: 2.7688 - val_accuracy: 0.0684\n",
      "Epoch 4/100\n",
      "493/871 [===============>..............] - ETA: 13s - loss: 2.7717 - accuracy: 0.0685"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_18076/949228634.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[0mes\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mEarlyStopping\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mmonitor\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;34m'val_loss'\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mverbose\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mpatience\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m5\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;31m#\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      2\u001B[0m \u001B[0mmc\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mModelCheckpoint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m'OneHand.h5'\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mmonitor\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;34m'val_accuracy'\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mverbose\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0msave_best_only\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mTrue\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;31m#\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 3\u001B[1;33m \u001B[0mhistory\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtwo_model\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfit\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtwo_x_train\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mtwo_y_train_1h\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mepochs\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m100\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mbatch_size\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m16\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mverbose\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mvalidation_split\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m0.2\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcallbacks\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mes\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mmc\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;32mC:\\ProgramData\\Miniconda3\\envs\\tf2\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001B[0m in \u001B[0;36merror_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     62\u001B[0m     \u001B[0mfiltered_tb\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     63\u001B[0m     \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 64\u001B[1;33m       \u001B[1;32mreturn\u001B[0m \u001B[0mfn\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     65\u001B[0m     \u001B[1;32mexcept\u001B[0m \u001B[0mException\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[1;33m:\u001B[0m  \u001B[1;31m# pylint: disable=broad-except\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     66\u001B[0m       \u001B[0mfiltered_tb\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0m_process_traceback_frames\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0me\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m__traceback__\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\ProgramData\\Miniconda3\\envs\\tf2\\lib\\site-packages\\keras\\engine\\training.py\u001B[0m in \u001B[0;36mfit\u001B[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001B[0m\n\u001B[0;32m   1382\u001B[0m                 _r=1):\n\u001B[0;32m   1383\u001B[0m               \u001B[0mcallbacks\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mon_train_batch_begin\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mstep\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1384\u001B[1;33m               \u001B[0mtmp_logs\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtrain_function\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0miterator\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1385\u001B[0m               \u001B[1;32mif\u001B[0m \u001B[0mdata_handler\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mshould_sync\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1386\u001B[0m                 \u001B[0mcontext\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0masync_wait\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\ProgramData\\Miniconda3\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001B[0m in \u001B[0;36merror_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    148\u001B[0m     \u001B[0mfiltered_tb\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    149\u001B[0m     \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 150\u001B[1;33m       \u001B[1;32mreturn\u001B[0m \u001B[0mfn\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    151\u001B[0m     \u001B[1;32mexcept\u001B[0m \u001B[0mException\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    152\u001B[0m       \u001B[0mfiltered_tb\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0m_process_traceback_frames\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0me\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m__traceback__\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\ProgramData\\Miniconda3\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001B[0m in \u001B[0;36m__call__\u001B[1;34m(self, *args, **kwds)\u001B[0m\n\u001B[0;32m    913\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    914\u001B[0m       \u001B[1;32mwith\u001B[0m \u001B[0mOptionalXlaContext\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_jit_compile\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 915\u001B[1;33m         \u001B[0mresult\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_call\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwds\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    916\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    917\u001B[0m       \u001B[0mnew_tracing_count\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mexperimental_get_tracing_count\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\ProgramData\\Miniconda3\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001B[0m in \u001B[0;36m_call\u001B[1;34m(self, *args, **kwds)\u001B[0m\n\u001B[0;32m    945\u001B[0m       \u001B[1;31m# In this case we have created variables on the first call, so we run the\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    946\u001B[0m       \u001B[1;31m# defunned version which is guaranteed to never create variables.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 947\u001B[1;33m       \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_stateless_fn\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwds\u001B[0m\u001B[1;33m)\u001B[0m  \u001B[1;31m# pylint: disable=not-callable\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    948\u001B[0m     \u001B[1;32melif\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_stateful_fn\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    949\u001B[0m       \u001B[1;31m# Release the lock early so that multiple threads can perform the call\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\ProgramData\\Miniconda3\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001B[0m in \u001B[0;36m__call__\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   2954\u001B[0m       (graph_function,\n\u001B[0;32m   2955\u001B[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001B[1;32m-> 2956\u001B[1;33m     return graph_function._call_flat(\n\u001B[0m\u001B[0;32m   2957\u001B[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001B[0;32m   2958\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\ProgramData\\Miniconda3\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001B[0m in \u001B[0;36m_call_flat\u001B[1;34m(self, args, captured_inputs, cancellation_manager)\u001B[0m\n\u001B[0;32m   1851\u001B[0m         and executing_eagerly):\n\u001B[0;32m   1852\u001B[0m       \u001B[1;31m# No tape is watching; skip to running the function.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1853\u001B[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001B[0m\u001B[0;32m   1854\u001B[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001B[0;32m   1855\u001B[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001B[1;32mC:\\ProgramData\\Miniconda3\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001B[0m in \u001B[0;36mcall\u001B[1;34m(self, ctx, args, cancellation_manager)\u001B[0m\n\u001B[0;32m    497\u001B[0m       \u001B[1;32mwith\u001B[0m \u001B[0m_InterpolateFunctionError\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    498\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mcancellation_manager\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 499\u001B[1;33m           outputs = execute.execute(\n\u001B[0m\u001B[0;32m    500\u001B[0m               \u001B[0mstr\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msignature\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mname\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    501\u001B[0m               \u001B[0mnum_outputs\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_num_outputs\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\ProgramData\\Miniconda3\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001B[0m in \u001B[0;36mquick_execute\u001B[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001B[0m\n\u001B[0;32m     52\u001B[0m   \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     53\u001B[0m     \u001B[0mctx\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mensure_initialized\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 54\u001B[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001B[0m\u001B[0;32m     55\u001B[0m                                         inputs, attrs, num_outputs)\n\u001B[0;32m     56\u001B[0m   \u001B[1;32mexcept\u001B[0m \u001B[0mcore\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_NotOkStatusException\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "es = EarlyStopping(monitor='val_loss', verbose=1, patience=5) #\n",
    "mc = ModelCheckpoint('TwoHand.h5', monitor='val_accuracy', verbose=1, save_best_only=True) #\n",
    "history = two_model.fit(two_x_train,two_y_train_1h,epochs=100,batch_size=16,verbose=1,validation_split=0.2, callbacks=[es, mc])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "es = EarlyStopping(monitor='val_loss', verbose=1, patience=5) #\n",
    "mc = ModelCheckpoint('OneHand.h5', monitor='val_accuracy', verbose=1, save_best_only=True) #\n",
    "\n",
    "history_one = two_model.fit(one_train_gen,epochs=60,verbose=1, validation_data=one_test_gen, callbacks=[es, mc])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "4350/4351 [============================>.] - ETA: 0s - loss: 2.7800 - accuracy: 0.0670\n",
      "Epoch 1: val_accuracy improved from -inf to 0.06690, saving model to TwoHand.h5\n",
      "4351/4351 [==============================] - 177s 40ms/step - loss: 2.7800 - accuracy: 0.0670 - val_loss: 2.7741 - val_accuracy: 0.0669\n",
      "Epoch 2/60\n",
      "4351/4351 [==============================] - ETA: 0s - loss: 2.7758 - accuracy: 0.0672\n",
      "Epoch 2: val_accuracy did not improve from 0.06690\n",
      "4351/4351 [==============================] - 176s 40ms/step - loss: 2.7758 - accuracy: 0.0672 - val_loss: 2.7825 - val_accuracy: 0.0593\n",
      "Epoch 3/60\n",
      "4351/4351 [==============================] - ETA: 0s - loss: 2.7750 - accuracy: 0.0634\n",
      "Epoch 3: val_accuracy did not improve from 0.06690\n",
      "4351/4351 [==============================] - 179s 41ms/step - loss: 2.7750 - accuracy: 0.0634 - val_loss: 2.7729 - val_accuracy: 0.0669\n",
      "Epoch 4/60\n",
      "4351/4351 [==============================] - ETA: 0s - loss: 2.7738 - accuracy: 0.0627\n",
      "Epoch 4: val_accuracy did not improve from 0.06690\n",
      "4351/4351 [==============================] - 175s 40ms/step - loss: 2.7738 - accuracy: 0.0627 - val_loss: 2.7725 - val_accuracy: 0.0660\n",
      "Epoch 5/60\n",
      "4350/4351 [============================>.] - ETA: 0s - loss: 2.7732 - accuracy: 0.0680\n",
      "Epoch 5: val_accuracy did not improve from 0.06690\n",
      "4351/4351 [==============================] - 174s 40ms/step - loss: 2.7732 - accuracy: 0.0681 - val_loss: 2.7715 - val_accuracy: 0.0666\n",
      "Epoch 6/60\n",
      "3449/4351 [======================>.......] - ETA: 32s - loss: 2.7737 - accuracy: 0.0642"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_18384/1520785647.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      2\u001B[0m \u001B[0mmc\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mModelCheckpoint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m'TwoHand.h5'\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mmonitor\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;34m'val_accuracy'\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mverbose\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0msave_best_only\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mTrue\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;31m#\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      3\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 4\u001B[1;33m \u001B[0mhistory_two\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtwo_model\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfit\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtwo_train_gen\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mepochs\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m60\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mverbose\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mvalidation_data\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mtwo_test_gen\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcallbacks\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mes\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mmc\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;32mC:\\ProgramData\\Miniconda3\\envs\\tf2\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001B[0m in \u001B[0;36merror_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     62\u001B[0m     \u001B[0mfiltered_tb\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     63\u001B[0m     \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 64\u001B[1;33m       \u001B[1;32mreturn\u001B[0m \u001B[0mfn\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     65\u001B[0m     \u001B[1;32mexcept\u001B[0m \u001B[0mException\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[1;33m:\u001B[0m  \u001B[1;31m# pylint: disable=broad-except\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     66\u001B[0m       \u001B[0mfiltered_tb\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0m_process_traceback_frames\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0me\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m__traceback__\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\ProgramData\\Miniconda3\\envs\\tf2\\lib\\site-packages\\keras\\engine\\training.py\u001B[0m in \u001B[0;36mfit\u001B[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001B[0m\n\u001B[0;32m   1382\u001B[0m                 _r=1):\n\u001B[0;32m   1383\u001B[0m               \u001B[0mcallbacks\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mon_train_batch_begin\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mstep\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1384\u001B[1;33m               \u001B[0mtmp_logs\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtrain_function\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0miterator\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1385\u001B[0m               \u001B[1;32mif\u001B[0m \u001B[0mdata_handler\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mshould_sync\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1386\u001B[0m                 \u001B[0mcontext\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0masync_wait\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\ProgramData\\Miniconda3\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001B[0m in \u001B[0;36merror_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    148\u001B[0m     \u001B[0mfiltered_tb\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    149\u001B[0m     \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 150\u001B[1;33m       \u001B[1;32mreturn\u001B[0m \u001B[0mfn\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    151\u001B[0m     \u001B[1;32mexcept\u001B[0m \u001B[0mException\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    152\u001B[0m       \u001B[0mfiltered_tb\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0m_process_traceback_frames\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0me\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m__traceback__\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\ProgramData\\Miniconda3\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001B[0m in \u001B[0;36m__call__\u001B[1;34m(self, *args, **kwds)\u001B[0m\n\u001B[0;32m    913\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    914\u001B[0m       \u001B[1;32mwith\u001B[0m \u001B[0mOptionalXlaContext\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_jit_compile\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 915\u001B[1;33m         \u001B[0mresult\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_call\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwds\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    916\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    917\u001B[0m       \u001B[0mnew_tracing_count\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mexperimental_get_tracing_count\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\ProgramData\\Miniconda3\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001B[0m in \u001B[0;36m_call\u001B[1;34m(self, *args, **kwds)\u001B[0m\n\u001B[0;32m    945\u001B[0m       \u001B[1;31m# In this case we have created variables on the first call, so we run the\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    946\u001B[0m       \u001B[1;31m# defunned version which is guaranteed to never create variables.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 947\u001B[1;33m       \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_stateless_fn\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwds\u001B[0m\u001B[1;33m)\u001B[0m  \u001B[1;31m# pylint: disable=not-callable\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    948\u001B[0m     \u001B[1;32melif\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_stateful_fn\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    949\u001B[0m       \u001B[1;31m# Release the lock early so that multiple threads can perform the call\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\ProgramData\\Miniconda3\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001B[0m in \u001B[0;36m__call__\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   2954\u001B[0m       (graph_function,\n\u001B[0;32m   2955\u001B[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001B[1;32m-> 2956\u001B[1;33m     return graph_function._call_flat(\n\u001B[0m\u001B[0;32m   2957\u001B[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001B[0;32m   2958\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\ProgramData\\Miniconda3\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001B[0m in \u001B[0;36m_call_flat\u001B[1;34m(self, args, captured_inputs, cancellation_manager)\u001B[0m\n\u001B[0;32m   1851\u001B[0m         and executing_eagerly):\n\u001B[0;32m   1852\u001B[0m       \u001B[1;31m# No tape is watching; skip to running the function.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1853\u001B[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001B[0m\u001B[0;32m   1854\u001B[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001B[0;32m   1855\u001B[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001B[1;32mC:\\ProgramData\\Miniconda3\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001B[0m in \u001B[0;36mcall\u001B[1;34m(self, ctx, args, cancellation_manager)\u001B[0m\n\u001B[0;32m    497\u001B[0m       \u001B[1;32mwith\u001B[0m \u001B[0m_InterpolateFunctionError\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    498\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mcancellation_manager\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 499\u001B[1;33m           outputs = execute.execute(\n\u001B[0m\u001B[0;32m    500\u001B[0m               \u001B[0mstr\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msignature\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mname\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    501\u001B[0m               \u001B[0mnum_outputs\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_num_outputs\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\ProgramData\\Miniconda3\\envs\\tf2\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001B[0m in \u001B[0;36mquick_execute\u001B[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001B[0m\n\u001B[0;32m     52\u001B[0m   \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     53\u001B[0m     \u001B[0mctx\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mensure_initialized\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 54\u001B[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001B[0m\u001B[0;32m     55\u001B[0m                                         inputs, attrs, num_outputs)\n\u001B[0;32m     56\u001B[0m   \u001B[1;32mexcept\u001B[0m \u001B[0mcore\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_NotOkStatusException\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "es = EarlyStopping(monitor='val_loss', verbose=1, patience=5) #\n",
    "mc = ModelCheckpoint('TwoHand.h5', monitor='val_accuracy', verbose=1, save_best_only=True) #\n",
    "\n",
    "history_two = two_model.fit(two_train_gen,epochs=60,verbose=1, validation_data=two_test_gen, callbacks=[es, mc])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}