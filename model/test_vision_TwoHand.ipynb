{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, Dense, MaxPool2D, Dropout, Flatten, AveragePooling2D\n",
    "from tensorflow.keras.utils import Sequence\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, confusion_matrix, recall_score, precision_score\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "import plotly.figure_factory as ff\n",
    "import plotly\n",
    "import plotly.graph_objs as go\n",
    "import pickle\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from statistics import mode, StatisticsError\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import TimeDistributed\n",
    "from keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras import initializers\n",
    "import time\n",
    "\n",
    "start = time.time()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading : 63.830064  s\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "bk_dataset = np.load('E:\\\\TwoHand_75Stack_5inputs.npz')\n",
    "\n",
    "data = bk_dataset['data']\n",
    "label = bk_dataset['label']\n",
    "\n",
    "t1 = time.time()\n",
    "print('loading : %f'%(t1-t0), ' s')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "data": {
      "text/plain": "((789, 75, 224, 224, 3), (789,))"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape , label.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "label = np.array(label)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(631, 75, 224, 224, 3) (158, 75, 224, 224, 3) (631,) (158,)\n"
     ]
    }
   ],
   "source": [
    "# Split Data\n",
    "# train 80% , test = 20%\n",
    "x_train, x_test, y_train, y_test = train_test_split(data, label, test_size=0.2, shuffle=True, random_state=42)\n",
    "print(x_train.shape, x_test.shape, y_train.shape, y_test.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "x_train /= 255.0\n",
    "x_test /= 255.0"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ทัณฑฆาต  ฤ  อะ  อา  อำ  อุ  อู  อ่  อ้  อ๊  อ๋  ฯ  เอ  แอ  ไม้หันอากาศ  \\\n",
      "0         0  0   0   0   0   0   1   0   0   0   0  0   0   0            0   \n",
      "1         0  0   0   0   0   0   0   1   0   0   0  0   0   0            0   \n",
      "2         1  0   0   0   0   0   0   0   0   0   0  0   0   0            0   \n",
      "3         1  0   0   0   0   0   0   0   0   0   0  0   0   0            0   \n",
      "4         1  0   0   0   0   0   0   0   0   0   0  0   0   0            0   \n",
      "5         1  0   0   0   0   0   0   0   0   0   0  0   0   0            0   \n",
      "6         0  0   0   0   0   0   0   0   0   0   0  1   0   0            0   \n",
      "7         0  0   0   1   0   0   0   0   0   0   0  0   0   0            0   \n",
      "8         0  0   1   0   0   0   0   0   0   0   0  0   0   0            0   \n",
      "9         0  0   0   0   0   0   0   0   0   1   0  0   0   0            0   \n",
      "10        0  0   0   0   0   0   0   0   0   0   0  1   0   0            0   \n",
      "11        1  0   0   0   0   0   0   0   0   0   0  0   0   0            0   \n",
      "12        0  0   0   0   0   0   0   0   0   0   1  0   0   0            0   \n",
      "13        0  0   0   0   1   0   0   0   0   0   0  0   0   0            0   \n",
      "14        0  0   0   0   0   0   0   0   0   0   1  0   0   0            0   \n",
      "15        0  0   0   0   0   0   0   0   1   0   0  0   0   0            0   \n",
      "16        0  0   0   0   0   0   0   0   0   0   0  0   0   0            1   \n",
      "17        0  0   0   0   1   0   0   0   0   0   0  0   0   0            0   \n",
      "18        0  0   0   1   0   0   0   0   0   0   0  0   0   0            0   \n",
      "19        0  0   0   0   0   0   0   0   0   0   0  0   0   0            0   \n",
      "\n",
      "    ไม้ไต่คู้  \n",
      "0           0  \n",
      "1           0  \n",
      "2           0  \n",
      "3           0  \n",
      "4           0  \n",
      "5           0  \n",
      "6           0  \n",
      "7           0  \n",
      "8           0  \n",
      "9           0  \n",
      "10          0  \n",
      "11          0  \n",
      "12          0  \n",
      "13          0  \n",
      "14          0  \n",
      "15          0  \n",
      "16          0  \n",
      "17          0  \n",
      "18          0  \n",
      "19          1  \n",
      "(631, 16)\n",
      "(158, 16)\n"
     ]
    }
   ],
   "source": [
    "y_train_1h = pd.get_dummies(y_train) # 1 hot format\n",
    "y_test_1h = pd.get_dummies(y_test)\n",
    "print(y_test_1h.head(20))\n",
    "print(y_train_1h.shape)\n",
    "print(y_test_1h.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "data": {
      "text/plain": "16"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_1h.shape[1]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, Dense, MaxPool2D, Dropout, Flatten, AveragePooling2D\n",
    "from tensorflow.keras.utils import Sequence\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, confusion_matrix, recall_score, precision_score\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "import plotly.figure_factory as ff\n",
    "import plotly\n",
    "import plotly.graph_objs as go\n",
    "import pickle\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from statistics import mode, StatisticsError\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import TimeDistributed\n",
    "from keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import regularizers\n",
    "import time"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm (LSTM)                 (None, 75, 128)           66560     \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 75, 64)            49408     \n",
      "                                                                 \n",
      " lstm_2 (LSTM)               (None, 32)                12416     \n",
      "                                                                 \n",
      " dense (Dense)               (None, 64)                2112      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 16)                528       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 133,104\n",
      "Trainable params: 133,104\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def LSTM_model_TwoHand():\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(LSTM(units = 128, input_shape=(75, 1), activation= 'tanh', return_sequences= True))\n",
    "    model.add(LSTM(units = 64, activation='tanh', return_sequences=True))\n",
    "    model.add(LSTM(units= 32, activation= 'tanh'))\n",
    "\n",
    "    # model.add(Flatten())\n",
    "    model.add(Dense(units = 64, activation = 'tanh'))\n",
    "    #model.add(Dropout(0.2))\n",
    "    model.add(Dense(units = 32, activation = 'tanh'))\n",
    "    #model.add(Dropout(0.2))\n",
    "    model.add(Dense(units= y_train_1h.shape[1], activation= 'softmax'))\n",
    "    model.compile(optimizer= 'adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "model = LSTM_model_TwoHand()\n",
    "model.build()\n",
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# DataGenerator\n",
    "class DataGenerator(Sequence):\n",
    "    def __init__(self, x_set, y_set, batch_size):\n",
    "        self.x, self.y = x_set, y_set\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.x) / float(self.batch_size)))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        batch_x = self.x[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        batch_y = self.y[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        return batch_x, batch_y\n",
    "\n",
    "train_gen = DataGenerator(x_train, y_train_1h, 8)\n",
    "test_gen = DataGenerator(x_test, y_test_1h, 8)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "`validation_split` is only supported for Tensors or NumPy arrays, found following types in the input: [<class '__main__.DataGenerator'>]",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_13940/2913627144.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[0mes\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mEarlyStopping\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mmonitor\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;34m'val_loss'\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mverbose\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mpatience\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m5\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;31m#\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      2\u001B[0m \u001B[0mmc\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mModelCheckpoint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m'test_bk_TwoHand.h5'\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mmonitor\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;34m'val_accuracy'\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mverbose\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0msave_best_only\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mTrue\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;31m#\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 3\u001B[1;33m \u001B[0mhistory\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mmodel\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfit\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtrain_gen\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mepochs\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m50\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mvalidation_data\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mtest_gen\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mverbose\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mvalidation_split\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m0.2\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcallbacks\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mes\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mmc\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      4\u001B[0m \u001B[1;31m# history = model.fit(x_train,y_train_1h,epochs=25,batch_size=2,verbose=1,validation_split=0.2)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\ProgramData\\Miniconda3\\envs\\tf2\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001B[0m in \u001B[0;36merror_handler\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m     65\u001B[0m     \u001B[1;32mexcept\u001B[0m \u001B[0mException\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[1;33m:\u001B[0m  \u001B[1;31m# pylint: disable=broad-except\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     66\u001B[0m       \u001B[0mfiltered_tb\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0m_process_traceback_frames\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0me\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m__traceback__\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 67\u001B[1;33m       \u001B[1;32mraise\u001B[0m \u001B[0me\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mwith_traceback\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mfiltered_tb\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mfrom\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     68\u001B[0m     \u001B[1;32mfinally\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     69\u001B[0m       \u001B[1;32mdel\u001B[0m \u001B[0mfiltered_tb\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\ProgramData\\Miniconda3\\envs\\tf2\\lib\\site-packages\\keras\\engine\\data_adapter.py\u001B[0m in \u001B[0;36mtrain_validation_split\u001B[1;34m(arrays, validation_split)\u001B[0m\n\u001B[0;32m   1476\u001B[0m   \u001B[0munsplitable\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[0mtype\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mt\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mfor\u001B[0m \u001B[0mt\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mflat_arrays\u001B[0m \u001B[1;32mif\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[0m_can_split\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mt\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1477\u001B[0m   \u001B[1;32mif\u001B[0m \u001B[0munsplitable\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1478\u001B[1;33m     raise ValueError(\n\u001B[0m\u001B[0;32m   1479\u001B[0m         \u001B[1;34m\"`validation_split` is only supported for Tensors or NumPy \"\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1480\u001B[0m         \"arrays, found following types in the input: {}\".format(unsplitable))\n",
      "\u001B[1;31mValueError\u001B[0m: `validation_split` is only supported for Tensors or NumPy arrays, found following types in the input: [<class '__main__.DataGenerator'>]"
     ]
    }
   ],
   "source": [
    "es = EarlyStopping(monitor='val_loss', verbose=1, patience=5) #\n",
    "mc = ModelCheckpoint('test_bk_TwoHand.h5', monitor='val_accuracy', verbose=1, save_best_only=True) #\n",
    "history = model.fit(train_gen,epochs=50,validation_data=test_gen, verbose=1, validation_split=0.2, callbacks=[es, mc])\n",
    "# history = model.fit(x_train,y_train_1h,epochs=25,batch_size=2,verbose=1,validation_split=0.2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}